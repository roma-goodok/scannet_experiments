{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roma/.virtualenvs/aseg_torch1/lib/python3.6/site-packages/kekas/keker.py:9: UserWarning: Error 'No module named 'apex''' during importing apex library. To use mixed precison you should install it from https://github.com/NVIDIA/apex\n",
      "  warnings.warn(f\"Error '{e}'' during importing apex library. To use mixed precison\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pdb import set_trace as st\n",
    "\n",
    "#import pretrainedmodels as pm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "#from albumentations import Compose, JpegCompression, CLAHE, RandomRotate90, Transpose, ShiftScaleRotate, \\\n",
    "#        Blur, OpticalDistortion, GridDistortion, HueSaturationValue, Flip, VerticalFlip\n",
    "\n",
    "from kekas import Keker, DataOwner, DataKek\n",
    "from kekas.transformations import Transformer, to_torch, normalize\n",
    "from kekas.metrics import accuracy\n",
    "from kekas.modules import Flatten, AdaptiveConcatPool2d\n",
    "from kekas.callbacks import Callback, Callbacks, DebuggerCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai_sparse #3D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparseconvnet as scn\n",
    "\n",
    "from fastai_sparse import utils, visualize\n",
    "from fastai_sparse.utils import log\n",
    "#from fastai_sparse.data import DataSourceConfig, MeshesDataset, SparseDataBunch\n",
    "#from fastai_sparse.learner import SparseModelConfig, Learner\n",
    "#from fastai_sparse.callbacks import TimeLogger, SaveModelCallback, CSVLogger\n",
    "from fastai_sparse.transforms import Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment environment and system metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neptune\n",
    "from neptune_callbacks import NeptuneMonitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_epoch': 384, 'max_lr': 0.5, 'wd': 3e-06}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params={'n_epoch': 256+128,\n",
    "        'max_lr': 0.5,\n",
    "        'wd':0.000003\n",
    "        }\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "with open('NEPTUNE_API_TOKEN.txt','r') as f:\n",
    "    NEPTUNE_API_TOKEN = f.readline().splitlines()[0]\n",
    "    \n",
    "neptune.init(api_token=NEPTUNE_API_TOKEN,\n",
    "             project_qualified_name='roma-goodok/fastai-sparse-scannet')\n",
    "\n",
    "\n",
    "\n",
    "# create experiment in the project defined above\n",
    "exp = neptune.create_experiment(params=params)\n",
    "print(exp.id)\n",
    "exp.append_tag('study')\n",
    "exp.append_tag('kekas')\n",
    "exp.append_tag('unet24')\n",
    "exp.append_tag('1cycle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kekas'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    experiment_name = exp.id\n",
    "except Exception as e:\n",
    "    experiment_name = \"kekas\"\n",
    "experiment_name        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "virtualenv:     (aseg_torch1) \n",
      "python:         3.6.8\n",
      "nvidia driver:  b'384.130'\n",
      "nvidia cuda:    9.0, V9.0.176\n",
      "cudnn:          7.1.4\n",
      "torch:          1.0.0\n",
      "pandas:         0.24.2\n",
      "kekas:          0.1.17\n",
      "fastai:         1.0.48\n",
      "fastai_sparse:  0.0.2.dev0\n"
     ]
    }
   ],
   "source": [
    "utils.watermark(pandas=True, kekas=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33md581ab5\u001b[m +neptune, + kekas (WIP)\r\n",
      "\u001b[33m6ae3ee1\u001b[m unet_24 run02, ryzen\r\n",
      "\u001b[33ma882e0a\u001b[m docs: Update README.md, INSTALL.md\r\n"
     ]
    }
   ],
   "source": [
    "!git log1 -n3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr 17 00:16:53 2019       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 384.130                Driver Version: 384.130                   |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:28:00.0  On |                  N/A |\r\n",
      "| 30%   58C    P0    70W / 250W |   1476MiB / 11163MiB |      3%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:29:00.0 Off |                  N/A |\r\n",
      "| 31%   60C    P2    77W / 250W |  11088MiB / 11172MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0      1442      G   /usr/lib/xorg/Xorg                           624MiB |\r\n",
      "|    0      2538      G   compiz                                       302MiB |\r\n",
      "|    0      4343      G   /usr/lib/firefox/firefox                     360MiB |\r\n",
      "|    0      5234      G   ...quest-channel-token=6448628850995738348    88MiB |\r\n",
      "|    0      7699      G   ...-token=0F1FA70BC62AF93F28E8D66C4BD2A655    87MiB |\r\n",
      "|    1     15423      C   ...a/.virtualenvs/fastai_sparse/bin/python 11077MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name:            AMD Ryzen 7 1700 Eight-Core Processor\r\n"
     ]
    }
   ],
   "source": [
    "!lscpu | grep \"Model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter notebook display options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:70% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "utils.wide_notebook()\n",
    "# uncomment this lines if you want switch off interactive and save visaulisation as screenshoots:\n",
    "# For rendering run command in terminal:    `chromium-browser --remote-debugging-port=9222`\n",
    "if  False:\n",
    "    visualize.options.interactive = False\n",
    "    visualize.options.save_images = True\n",
    "    visualize.options.verbose = True\n",
    "    visualize.options.filename_pattern_image = Path('images', experiment_name, 'fig_{fig_number}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see how download and preprocess data by the following link from fastai_sparse library: https://github.com/goodok/fastai_sparse/tree/master/examples/scannet/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scene0000_01.merged.ply']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SOURCE_DIR = Path('data', 'scannet_merged_ply')\n",
    "assert SOURCE_DIR.exists(), \"Run prepare_data.ipynb\"\n",
    "\n",
    "definition_of_spliting_dir = Path('data', 'ScanNet_Tasks_Benchmark')\n",
    "assert definition_of_spliting_dir.exists()\n",
    "\n",
    "\n",
    "os.listdir(SOURCE_DIR / 'scene0000_01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_files(path, ext='merged.ply'):\n",
    "    pattern = str(path / '*' / ('*' + ext))\n",
    "    fnames = glob.glob(pattern)\n",
    "    return fnames\n",
    "\n",
    "def get_df_list(verbose=0):\n",
    "    # train /valid / test splits\n",
    "    fn_lists = {}\n",
    "\n",
    "    fn_lists['train'] = definition_of_spliting_dir / 'scannetv1_train.txt'\n",
    "    fn_lists['valid'] = definition_of_spliting_dir / 'scannetv1_val.txt'\n",
    "    fn_lists['test'] = definition_of_spliting_dir / 'scannetv1_test.txt'\n",
    "\n",
    "    for datatype in ['train', 'valid', 'test']:\n",
    "        assert fn_lists[datatype].exists(), datatype\n",
    "\n",
    "    dfs = {}\n",
    "    total = 0\n",
    "    for datatype in ['train', 'valid', 'test']:\n",
    "        df = pd.read_csv(fn_lists[datatype], header=None, names=['example_id'])\n",
    "        df = df.assign(datatype=datatype)\n",
    "        df = df.assign(subdir=df.example_id)\n",
    "        df = df.sort_values('example_id')\n",
    "        dfs[datatype] = df\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"{datatype:5} counts: {len(df):>4}\")\n",
    "        \n",
    "        total += len(df)\n",
    "    if verbose:\n",
    "        print(f\"total:     {total}\")\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train counts: 1045\n",
      "valid counts:  156\n",
      "test  counts:  312\n",
      "total:     1513\n"
     ]
    }
   ],
   "source": [
    "df_list = get_df_list(verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>datatype</th>\n",
       "      <th>subdir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>scene0000_00</td>\n",
       "      <td>train</td>\n",
       "      <td>scene0000_00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>scene0000_01</td>\n",
       "      <td>train</td>\n",
       "      <td>scene0000_01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>scene0000_02</td>\n",
       "      <td>train</td>\n",
       "      <td>scene0000_02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>scene0001_00</td>\n",
       "      <td>train</td>\n",
       "      <td>scene0001_00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>scene0001_01</td>\n",
       "      <td>train</td>\n",
       "      <td>scene0001_01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       example_id datatype        subdir\n",
       "827  scene0000_00    train  scene0000_00\n",
       "828  scene0000_01    train  scene0000_01\n",
       "829  scene0000_02    train  scene0000_02\n",
       "496  scene0001_00    train  scene0001_00\n",
       "497  scene0001_01    train  scene0001_01"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list['train'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scene0000_00.merged.ply']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(os.path.join(SOURCE_DIR, 'scene0000_00'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai_sparse.data  import MeshItem, PointsItem\n",
    "from fastai_sparse.learner import SparseModelConfig\n",
    "import transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at first we need to create a reader function that will define how image will be opened\n",
    "def reader_fn(i, row):\n",
    "    fn = SOURCE_DIR / row['subdir'] / f'{row[\"example_id\"]}.merged.ply'\n",
    "    m = MeshItem.from_file(fn, label_field='label')\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MeshItem (scene0000_00.merged.ply)\n",
      "vertices:                shape: (81369, 3)            dtype: float64        min:   -0.01657,  max:    8.74040,  mean:    3.19051\n",
      "faces:                   shape: (153587, 3)           dtype: int64          min:          0,  max:      81368,  mean: 40549.68796\n",
      "colors:                  shape: (81369, 4)            dtype: uint8          min:    1.00000,  max:  255.00000,  mean:  145.80430\n",
      "labels:                  shape: (81369,)              dtype: uint16         min:    0.00000,  max:  230.00000,  mean:   12.97057\n",
      "Colors from vertices\n",
      "Labels from vertices\n"
     ]
    }
   ],
   "source": [
    "m = reader_fn(0, df_list['train'].iloc[0])\n",
    "m.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.is_colors_from_vertices, m.is_labels_from_vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map relevant classes to {0,1,...,19}, and ignored classes to -100\n",
    "remapper = np.ones(3000, dtype=np.int32) * (-100)\n",
    "for i, x in enumerate([1,2,3,4,5,6,7,8,9,10,11,12,14,16,24,28,33,34,36,39]):\n",
    "    remapper[x] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_TFMS = [T.to_points_cloud(method='vertices', normals=False), \n",
    "            T.remap_labels(remapper=remapper, inplace=False),\n",
    "            T.colors_normalize(),\n",
    "            T.normalize_spatial(),\n",
    "           ]\n",
    "\n",
    "_scale = 20\n",
    "\n",
    "AUGS_TRAIN = [\n",
    "    T.noise_affine(amplitude=0.1),\n",
    "    T.flip_x(p=0.5),\n",
    "    T.scale(scale=_scale),\n",
    "    T.rotate_XY(),\n",
    "    \n",
    "    T.elastic(gran=6 * _scale // 50, mag=40 * _scale / 50),\n",
    "    T.elastic(gran=20 * _scale // 50, mag=160 * _scale / 50),\n",
    "    \n",
    "    T.specific_translate(full_scale=4096),\n",
    "    T.crop_points(low=0, high=4096),\n",
    "    T.colors_noise(amplitude=0.1),\n",
    "]\n",
    "\n",
    "AUGS_VALID = [\n",
    "    T.noise_affine(amplitude=0.1),\n",
    "    T.flip_x(p=0.5),\n",
    "    T.scale(scale=_scale),\n",
    "    T.rotate_XY(),\n",
    "\n",
    "    T.translate(offset=4096 / 2),\n",
    "    T.rand_translate(offset=(-2, 2, 3)),  # low, high, dimention\n",
    "    \n",
    "    T.specific_translate(full_scale=4096),\n",
    "    T.crop_points(low=0, high=4096),\n",
    "    T.colors_noise(amplitude=0.1),\n",
    "        \n",
    "    ]\n",
    "\n",
    "SPARSE_TFMS = [\n",
    "    T.merge_features(ones=False, colors=True, normals=False),\n",
    "    T.to_sparse_voxels(),\n",
    "]\n",
    "\n",
    "\n",
    "# reimplement to_torch\n",
    "def _to_torch(x):\n",
    "    x.coords \n",
    "    x.features\n",
    "    x.labels\n",
    "    \n",
    "    return x\n",
    "\n",
    "to_torch = Transform(_to_torch)\n",
    "\n",
    "# merge_fn\n",
    "def merge_fn(examples):\n",
    "    # stack\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function kekas.transformations.to_torch(scale_factor:float=255.0) -> Callable>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: pull request\n",
    "\n",
    "\"\"\"\n",
    "For usage in kekas\n",
    "\"\"\"\n",
    "\n",
    "class Compose(object):\n",
    "    \"\"\"Composes several transforms together.\n",
    "    Args:\n",
    "        transforms (list of ``Transform`` objects): list of transforms to compose.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, item):\n",
    "        # Apply .resolve method for random transformation\n",
    "        # See alse ItemBase.apply_tfms\n",
    "        \n",
    "        # if flow of affine transforms is ended, then refresh (apply)\n",
    "        is_affine = [getattr(tfm.tfm, '_wrap', None) == 'affine' for tfm in self.transforms]\n",
    "        is_do_refresh = np.diff(is_affine, append=0) == -1\n",
    "\n",
    "        # x = item.clone()\n",
    "        x = item\n",
    "        for tfm, do_refresh in zip(self.transforms, is_do_refresh):\n",
    "\n",
    "            tfm.resolve()\n",
    "\n",
    "            x = tfm(x)\n",
    "            if do_refresh:\n",
    "                x.refresh()\n",
    "\n",
    "        return x\n",
    "\n",
    "    def __repr__(self):\n",
    "        format_string = self.__class__.__name__ + '('\n",
    "        for t in self.transforms:\n",
    "            format_string += '\\n'\n",
    "            format_string += '    {0}'.format(t)\n",
    "        format_string += '\\n)'\n",
    "        return format_string\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(dataset_key):\n",
    "        \n",
    "    return  Compose(PRE_TFMS + AUGS_TRAIN + SPARSE_TFMS), Compose(PRE_TFMS + AUGS_VALID + SPARSE_TFMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataKeks creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df_list['train']\n",
    "val_df = df_list['valid']\n",
    "\n",
    "# now let's create DataKeks\n",
    "train_tfms, val_tfms = get_transforms(\"mesh\")\n",
    "\n",
    "train_dk = DataKek(df=train_df, reader_fn=reader_fn, transforms=train_tfms)\n",
    "val_dk = DataKek(df=val_df, reader_fn=reader_fn, transforms=val_tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: scene0000_00.merged\n",
      "coords                   shape: (81369, 3)            dtype: int64          min:        485,  max:       2225,  mean: 1361.89110\n",
      "features                 shape: (81369, 3)            dtype: float32        min:   -1.01692,  max:    1.13572,  mean:   -0.08030\n",
      "x                        shape: (81369,)              dtype: int64          min:       2000,  max:       2225,  mean: 2113.28009\n",
      "y                        shape: (81369,)              dtype: int64          min:       1351,  max:       1558,  mean: 1454.87349\n",
      "z                        shape: (81369,)              dtype: int64          min:        485,  max:        575,  mean:  517.51972\n",
      "labels                   shape: (81369,)              dtype: int64          min:       -100,  max:         17,  mean:  -48.51506\n",
      "voxels: 59185\n",
      "points / voxels: 1.3748247022049507\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ce4110388644421a198b8042dd57bda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "b = train_dk[0]\n",
    "b.describe()\n",
    "b.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and DataLoaders\n",
    "batch_size = 32\n",
    "workers = 8\n",
    "\n",
    "train_dl = DataLoader(train_dk, batch_size=batch_size, num_workers=workers, shuffle=True, drop_last=True, collate_fn=merge_fn)\n",
    "val_dl = DataLoader(val_dk, batch_size=batch_size, num_workers=workers, shuffle=False, collate_fn=merge_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseModelConfig;\n",
       "   resolution: 50\n",
       "   spatial_size: 4096\n",
       "   dimension: 3\n",
       "   block_reps: 1\n",
       "   m: 16\n",
       "   num_planes: [16, 32, 48, 64, 80, 96, 112]\n",
       "   residual_blocks: False\n",
       "   num_classes: 20\n",
       "   num_input_features: 3\n",
       "   mode: 4\n",
       "   downsample: [2, 2]\n",
       "   bias: False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spatial_size  is full_scale\n",
    "model_config = SparseModelConfig(spatial_size=4096, num_classes=20, num_input_features=3, mode=4,\n",
    "                                 m=16, num_planes_coeffs=[1, 2, 3, 4, 5, 6, 7])\n",
    "model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        nn.Module.__init__(self)\n",
    "        self.sparseModel = scn.Sequential(\n",
    "            scn.InputLayer(cfg.dimension, cfg.spatial_size, mode=cfg.mode),\n",
    "            scn.SubmanifoldConvolution(cfg.dimension, nIn=cfg.num_input_features, nOut=cfg.m, filter_size=3, bias=cfg.bias),\n",
    "            scn.UNet(cfg.dimension, cfg.block_reps, cfg.num_planes, residual_blocks=cfg.residual_blocks, downsample=cfg.downsample),\n",
    "            scn.BatchNormReLU(cfg.m),\n",
    "            scn.OutputLayer(cfg.dimension),\n",
    "        )\n",
    "        self.linear = nn.Linear(cfg.m, cfg.num_classes)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        x = [xb['coords'], xb['features']]\n",
    "        x = self.sparseModel(x)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "model = Model(model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the three whales of your pipelane are: the data, the model and the loss (hi, Jeremy)\n",
    "\n",
    "# the data is represented in Kekas by DataOwner. It is a namedtuple with three fields:\n",
    "# 'train_dl', 'val_dl', 'test_dl'\n",
    "# For training process we will need at least two of them, and we can skip 'test_dl' for now\n",
    "# so we will initialize it with `None` value.\n",
    "dataowner = DataOwner(train_dl, val_dl, None)\n",
    "\n",
    "# model is just a pytorch nn.Module, that we created vefore\n",
    "#model = Net(num_classes=2)\n",
    "\n",
    "# loss or criterion is also a pytorch nn.Module. For multiloss scenarios it can be a list of nn.Modules\n",
    "# for our simple example let's use the standart cross entopy criterion\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also we need to specify, what model will do with each batch of data on each iteration\n",
    "# We should define a `step_fn` function\n",
    "# The code below repeats a `keker.default_step_fn` code to provide you with a concept of step function\n",
    "\n",
    "def step_fn(model: torch.nn.Module,\n",
    "            batch: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Determine what your model will do with your data.\n",
    "\n",
    "    Args:\n",
    "        model: the pytorch module to pass input in\n",
    "        batch: the batch of data from the DataLoader\n",
    "\n",
    "    Returns:\n",
    "        The models forward pass results\n",
    "    \"\"\"\n",
    "    \n",
    "    # you could define here whatever logic you want\n",
    "    inp = batch  # here we get an \"image\" from our dataset\n",
    "    return model(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# previous preparations was mostly out of scope of Kekas library (except DataKeks creation)\n",
    "# Now let's dive into kekas a little bit\n",
    "\n",
    "# firstly, we create a Keker - the core Kekas class, that provides all the keks for your pipeline\n",
    "keker = Keker(model=model,\n",
    "              dataowner=dataowner,\n",
    "              criterion=criterion,\n",
    "              step_fn=step_fn,                    # previosly defined step function\n",
    "              target_key=\"label\",                 # remember, we defined it in the reader_fn for DataKek?              \n",
    "              opt=torch.optim.Adam,               # optimizer class. if note specifiyng, \n",
    "                                                  # an SGD is using by default\n",
    "              opt_params={\"weight_decay\": 1e-5})  # optimizer kwargs in dict format (optional too)\n",
    "\n",
    "# Actually, there are a lot of params for kekers, but this out of scope of this example\n",
    "# you can read about them in Keker's docstring (but who really reads the docs, huh?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before the start of the finetuning procedure let's freeeze all the layers except the last one - the head\n",
    "# the `freeze` method is mostly inspired (or stolen) from fastai\n",
    "# but you should define a model's attribute to deal with\n",
    "# for example, our model is actually model.net, so we need to specify the 'net' attr\n",
    "# also this method does not freezes batchnorm layers by default. To change this set `freeze_bn=True`\n",
    "\n",
    "#keker.freeze(model_attr=\"net\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate Find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   0% 0/32 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Traceback (most recent call last):\n  File \"/home/roma/.virtualenvs/aseg_torch1/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 138, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/roma/.virtualenvs/aseg_torch1/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 138, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/roma/.virtualenvs/aseg_torch1/lib/python3.6/site-packages/kekas/data.py\", line 24, in __getitem__\n    datum = self.reader_fn(ind, data_dict)\n  File \"<ipython-input-20-2108fa428d41>\", line 3, in reader_fn\n    fn = SOURCE_DIR / row.subdir / f'{row.example_id}.merged.ply'\nAttributeError: 'dict' object has no attribute 'subdir'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-2e36661489c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# to see them start a tensorboard with `--logdir /path/to/logdir`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# OR you can use keker.plot_kek_lr method (see cell below)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mkeker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkek_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"logdir\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/aseg_torch1/lib/python3.6/site-packages/kekas/keker.py\u001b[0m in \u001b[0;36mkek_lr\u001b[0;34m(self, final_lr, logdir, init_lr, n_steps, opt, opt_params)\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCallbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore_callbacks\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlrfinder_cb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             self.kek(lr=init_lr, epochs=n_epochs, skip_val=True, logdir=logdir,\n\u001b[0;32m--> 409\u001b[0;31m                      opt=opt, opt_params=opt_params)\n\u001b[0m\u001b[1;32m    410\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/aseg_torch1/lib/python3.6/site-packages/kekas/keker.py\u001b[0m in \u001b[0;36mkek\u001b[0;34m(self, lr, epochs, skip_val, opt, opt_params, sched, sched_params, stop_iter, logdir, cp_saver_params, early_stop_params)\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mskip_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/aseg_torch1/lib/python3.6/site-packages/kekas/keker.py\u001b[0m in \u001b[0;36m_run_epoch\u001b[0;34m(self, epoch, epochs)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/aseg_torch1/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    635\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreorder_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[0;31m# Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/aseg_torch1/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_next_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_put_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Traceback (most recent call last):\n  File \"/home/roma/.virtualenvs/aseg_torch1/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 138, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/roma/.virtualenvs/aseg_torch1/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 138, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/roma/.virtualenvs/aseg_torch1/lib/python3.6/site-packages/kekas/data.py\", line 24, in __getitem__\n    datum = self.reader_fn(ind, data_dict)\n  File \"<ipython-input-20-2108fa428d41>\", line 3, in reader_fn\n    fn = SOURCE_DIR / row.subdir / f'{row.example_id}.merged.ply'\nAttributeError: 'dict' object has no attribute 'subdir'\n"
     ]
    }
   ],
   "source": [
    "# let's find an 'optimal' learning rate with learning rate find procedure\n",
    "# for details please see the fastai course and this articles:\n",
    "# https://arxiv.org/abs/1803.09820\n",
    "# https://sgugger.github.io/how-do-you-find-a-good-learning-rate.html\n",
    "\n",
    "# NOTE: this is an optional step and you can skip it and use your favorite learning rate\n",
    "\n",
    "# you MUST specify the logdir to see graphics\n",
    "# keker will write a tensorboard logs into this folder\n",
    "# to see them start a tensorboard with `--logdir /path/to/logdir`\n",
    "# OR you can use keker.plot_kek_lr method (see cell below)\n",
    "keker.kek_lr(final_lr=0.1, logdir=\"logdir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# from kekas Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe creation and train/val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a pandas DataFrame to help us with data handling\n",
    "root_dir = Path(\"PetImages/\")  # path to Cats and Dogs dataset root directory\n",
    "\n",
    "fpaths = []\n",
    "labels = []\n",
    "for d in root_dir.iterdir():\n",
    "    for f in d.iterdir():\n",
    "        img = cv2.imread(str(f))  # some files there are corrupted, so add only good ones\n",
    "        if img is not None:\n",
    "            labels.append(d.name)\n",
    "            fpaths.append(str(f))\n",
    "\n",
    "df = pd.DataFrame(data={\"fpath\": fpaths, \"label\": labels})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# split dataset to train and val parts\n",
    "train_df, val_df = train_test_split(df, test_size=2000)\n",
    "train_df.shape, val_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train and val datasets using DataKek class - a pytorch Dataset that uses pandas DataFrame as data source\n",
    "\n",
    "# at first we need to create a reader function that will define how image will be opened\n",
    "def reader_fn(i, row):\n",
    "    # it always gets i and row as parameters\n",
    "    # where i is an index of dataframe and row is a dataframes row\n",
    "    image = cv2.imread(row[\"fpath\"])[:,:,::-1]  # BGR -> RGB\n",
    "    if row[\"label\"] == \"Dog\":\n",
    "        label = 0\n",
    "    else:\n",
    "        label = 1\n",
    "    return {\"image\": image, \"label\": label}\n",
    "\n",
    "\n",
    "# Then we should create transformations/augmentations\n",
    "# We will use awesome https://github.com/albu/albumentations library\n",
    "def augs(p=0.5):\n",
    "    return Compose([\n",
    "        CLAHE(),\n",
    "        RandomRotate90(),\n",
    "        Transpose(),\n",
    "        ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.50, rotate_limit=45, p=.75),\n",
    "        Blur(blur_limit=3),\n",
    "        OpticalDistortion(),\n",
    "        GridDistortion(),\n",
    "        HueSaturationValue()\n",
    "    ], p=p)\n",
    "\n",
    "def get_transforms(dataset_key, size, p):\n",
    "    # we need to use a Transformer class to apply transformations to DataKeks elements\n",
    "    # dataset_key is an image key in dict returned by reader_fn\n",
    "    \n",
    "    PRE_TFMS = Transformer(dataset_key, lambda x: cv2.resize(x, (size, size)))\n",
    "\n",
    "    AUGS = Transformer(dataset_key, lambda x: augs()(image=x)[\"image\"])\n",
    "\n",
    "    NRM_TFMS = transforms.Compose([\n",
    "        Transformer(dataset_key, to_torch()),\n",
    "        Transformer(dataset_key, normalize())\n",
    "    ])\n",
    "    \n",
    "    train_tfms = transforms.Compose([PRE_TFMS, AUGS, NRM_TFMS])\n",
    "    val_tfms = transforms.Compose([PRE_TFMS, NRM_TFMS])  # because we don't want to augment val set yet\n",
    "    \n",
    "    return train_tfms, val_tfms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataKeks creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's create DataKeks\n",
    "train_tfms, val_tfms = get_transforms(\"image\", 224, 0.5)\n",
    "\n",
    "train_dk = DataKek(df=train_df, reader_fn=reader_fn, transforms=train_tfms)\n",
    "val_dk = DataKek(df=val_df, reader_fn=reader_fn, transforms=val_tfms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and DataLoaders\n",
    "batch_size = 32\n",
    "workers = 8\n",
    "\n",
    "train_dl = DataLoader(train_dk, batch_size=batch_size, num_workers=workers, shuffle=True, drop_last=True)\n",
    "val_dl = DataLoader(val_dk, batch_size=batch_size, num_workers=workers, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a simple neural network using pretrainedmodels library\n",
    "# https://github.com/Cadene/pretrained-models.pytorch\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_classes: int,\n",
    "            p: float = 0.5,\n",
    "            pooling_size: int = 2,\n",
    "            last_conv_size: int = 2048,\n",
    "            arch: str = \"se_resnext50_32x4d\",\n",
    "            pretrained: str = \"imagenet\") -> None:\n",
    "        \"\"\"A simple model to finetune.\n",
    "        \n",
    "        Args:\n",
    "            num_classes: the number of target classes, the size of the last layer's output\n",
    "            p: dropout probability\n",
    "            pooling_size: the size of the result feature map after adaptive pooling layer\n",
    "            last_conv_size: size of the flatten last backbone conv layer\n",
    "            arch: the name of the architecture form pretrainedmodels\n",
    "            pretrained: the mode for pretrained model from pretrainedmodels\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        net = pm.__dict__[arch](pretrained=pretrained)\n",
    "        modules = list(net.children())[:-2]  # delete last layers: pooling and linear\n",
    "        \n",
    "        # add custom head\n",
    "        modules += [nn.Sequential(\n",
    "            # AdaptiveConcatPool2d is a concat of AdaptiveMaxPooling and AdaptiveAveragePooling \n",
    "            AdaptiveConcatPool2d(size=pooling_size),\n",
    "            Flatten(),\n",
    "            nn.BatchNorm1d(2 * pooling_size * pooling_size * last_conv_size),\n",
    "            nn.Dropout(p),\n",
    "            nn.Linear(2 * pooling_size * pooling_size * last_conv_size, num_classes)\n",
    "        )]\n",
    "        self.net = nn.Sequential(*modules)\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.net(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the three whales of your pipelane are: the data, the model and the loss (hi, Jeremy)\n",
    "\n",
    "# the data is represented in Kekas by DataOwner. It is a namedtuple with three fields:\n",
    "# 'train_dl', 'val_dl', 'test_dl'\n",
    "# For training process we will need at least two of them, and we can skip 'test_dl' for now\n",
    "# so we will initialize it with `None` value.\n",
    "dataowner = DataOwner(train_dl, val_dl, None)\n",
    "\n",
    "# model is just a pytorch nn.Module, that we created vefore\n",
    "model = Net(num_classes=2)\n",
    "\n",
    "# loss or criterion is also a pytorch nn.Module. For multiloss scenarios it can be a list of nn.Modules\n",
    "# for our simple example let's use the standart cross entopy criterion\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also we need to specify, what model will do with each batch of data on each iteration\n",
    "# We should define a `step_fn` function\n",
    "# The code below repeats a `keker.default_step_fn` code to provide you with a concept of step function\n",
    "\n",
    "def step_fn(model: torch.nn.Module,\n",
    "            batch: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Determine what your model will do with your data.\n",
    "\n",
    "    Args:\n",
    "        model: the pytorch module to pass input in\n",
    "        batch: the batch of data from the DataLoader\n",
    "\n",
    "    Returns:\n",
    "        The models forward pass results\n",
    "    \"\"\"\n",
    "    \n",
    "    # you could define here whatever logic you want\n",
    "    inp = batch[\"image\"]  # here we get an \"image\" from our dataset\n",
    "    return model(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# previous preparations was mostly out of scope of Kekas library (except DataKeks creation)\n",
    "# Now let's dive into kekas a little bit\n",
    "\n",
    "# firstly, we create a Keker - the core Kekas class, that provides all the keks for your pipeline\n",
    "keker = Keker(model=model,\n",
    "              dataowner=dataowner,\n",
    "              criterion=criterion,\n",
    "              step_fn=step_fn,                    # previosly defined step function\n",
    "              target_key=\"label\",                 # remember, we defined it in the reader_fn for DataKek?\n",
    "              metrics={\"acc\": accuracy},          # optional, you can not specify any metrics at all\n",
    "              opt=torch.optim.Adam,               # optimizer class. if note specifiyng, \n",
    "                                                  # an SGD is using by default\n",
    "              opt_params={\"weight_decay\": 1e-5})  # optimizer kwargs in dict format (optional too)\n",
    "\n",
    "# Actually, there are a lot of params for kekers, but this out of scope of this example\n",
    "# you can read about them in Keker's docstring (but who really reads the docs, huh?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before the start of the finetuning procedure let's freeeze all the layers except the last one - the head\n",
    "# the `freeze` method is mostly inspired (or stolen) from fastai\n",
    "# but you should define a model's attribute to deal with\n",
    "# for example, our model is actually model.net, so we need to specify the 'net' attr\n",
    "# also this method does not freezes batchnorm layers by default. To change this set `freeze_bn=True`\n",
    "keker.freeze(model_attr=\"net\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate Find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# let's find an 'optimal' learning rate with learning rate find procedure\n",
    "# for details please see the fastai course and this articles:\n",
    "# https://arxiv.org/abs/1803.09820\n",
    "# https://sgugger.github.io/how-do-you-find-a-good-learning-rate.html\n",
    "\n",
    "# NOTE: this is an optional step and you can skip it and use your favorite learning rate\n",
    "\n",
    "# you MUST specify the logdir to see graphics\n",
    "# keker will write a tensorboard logs into this folder\n",
    "# to see them start a tensorboard with `--logdir /path/to/logdir`\n",
    "# OR you can use keker.plot_kek_lr method (see cell below)\n",
    "keker.kek_lr(final_lr=0.1, logdir=\"/path/to/logdir\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Learning Rate find results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zoom in plot to see on which step the loss was still decreasing\n",
    "# and choose LR from this step\n",
    "keker.plot_kek_lr(logdir=\"/path/to/logdir\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Kek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok, now let's start training!\n",
    "# It's as simple as:\n",
    "keker.kek(lr=1e-5, epochs=3)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kek with different optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SomeKekasUser: Wait, and what if I want to train with the different optimizer?\n",
    "#\n",
    "# Me:\n",
    "keker.kek(lr=1e-5, \n",
    "          epochs=1,\n",
    "          opt=torch.optim.RMSprop,            # optimizer class\n",
    "          opt_params={\"weight_decay\": 1e-5})  # optimizer kwargs in dict format (if you want)\n",
    "\n",
    "# by default, the optimizer specified on Keker initialization is used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kek with scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SomeKekasUser: OK, and what if I want to use a pytorch scheduler?\n",
    "#\n",
    "# Me:\n",
    "keker.kek(lr=1e-5,\n",
    "          epochs=2,\n",
    "          sched=torch.optim.lr_scheduler.StepLR,       # pytorch lr scheduler class\n",
    "          sched_params={\"step_size\":1, \"gamma\": 0.9})  # schedulres kwargas in dict format\n",
    "\n",
    "# by default, no scheduler is using"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log your keks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SomeKekasUser: How about logging?\n",
    "#\n",
    "# Me:\n",
    "keker.kek(lr=1e-5,\n",
    "          epochs=1,\n",
    "          logdir=\"/mnt/hdd3_4/belskikh/keks/forplot\")\n",
    "\n",
    "# It will create a `train` and `val` subfolders in logdir, and will write tensorboard logs into them\n",
    "# to see them start a tensorboard with `--logdir /path/to/logdir`\n",
    "# OR you can use keker.plot_kek method! (see cell below)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot your keks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kekas uses plotly lib and tensorboard logs to plot inside NB\n",
    "keker.plot_kek(logdir=\"/path/to/logdir\",  # path to logdir with logs to plot\n",
    "               step=\"batch\",              # (optional) default is \"step\". another option is \"epoch\"\n",
    "                                          # It determines discreteness of ploting\n",
    "               metrics=[\"loss\",           # (optional) list of metrics names\n",
    "                        \"acc\",            # by default [\"loss\", \"lr\"] is using\n",
    "                        \"lr\"],            # the order of the names determines the order of the plot\n",
    "                                          # NOTE: names of metrics must match names in metrics dict\n",
    "                                          # which was specified on Keker init step\n",
    "               height=1200,               # (optional) height of the total plot \n",
    "               width=800)                 # (optional) width of the total plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoints saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SomeKekasUser: Also I want to save best checkpoints to later use them for SWA or ensembling!\n",
    "#                And I want to measure them by custom metric, control their number, specify their name prefix,\n",
    "#                and control what I need - minimize or maximize metric!\n",
    "# Me: Here it is:\n",
    "keker.kek(lr=1e-5,\n",
    "          epochs=1,\n",
    "          cp_saver_params={\n",
    "              \"savedir\": \"/path/to/save/dir\",  # a directory for checkpoints\n",
    "              \"metric\": \"acc\",  # (optional) from `metrics` dict on Keker init. \n",
    "                                # default is validation loss\n",
    "              \"n_best\": 3,      # (optional) default is 3\n",
    "              \"prefix\": \"kek\",  # (optional) default prefix is `checkpoint`\n",
    "              \"mode\": \"max\"     # (optional) default is 'min'\n",
    "          })   \n",
    "\n",
    "# It will create a `savedir` directory, and will save best checkpoints there\n",
    "# with naming `{prefix}.{epoch_num}.h5`. The best checkpoint will be dublicated with `{prefix}.best.h5` name\n",
    "# look at the report down here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SomeKekasUser: Allright, and I don't want to train model, if validation loss doesn't improve for several epochs.\n",
    "# \n",
    "# Me: You mean, early stopping? Here:\n",
    "keker.kek(lr=1e-5,\n",
    "          epochs=1, \n",
    "          early_stop_params={\n",
    "              \"patience\": 3,   # number of bad epochs to wait before stopping\n",
    "              \"metric\": \"acc\", # (optional) metric name from 'metric' dict. default is val loss\n",
    "              \"mode\": \"min\",   # (optional) what you want from you metric, max or min? default is 'min'\n",
    "              \"min_delta\": 0   # (optional) a minimum delta to count an epoch as 'bad'\n",
    "          })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SomeAdvancedKekasUser: I WANT IT ALL!\n",
    "# \n",
    "# Me: Well, okay then...\n",
    "keker.kek(lr=1e-5,\n",
    "          epochs=5,\n",
    "          opt=torch.optim.RMSprop,\n",
    "          opt_params={\"weight_decay\": 1e-5},\n",
    "          sched=torch.optim.lr_scheduler.StepLR,\n",
    "          sched_params={\"step_size\":1, \"gamma\": 0.9},\n",
    "          logdir=\"/path/to/logdir\",\n",
    "          cp_saver_params={\n",
    "              \"savedir\": \"/path/to/save/dir\",  \n",
    "              \"metric\": \"acc\",  \n",
    "              \"n_best\": 3,      \n",
    "              \"prefix\": \"kek\",  \n",
    "              \"mode\": \"max\"},     \n",
    "          early_stop_params={\n",
    "              \"patience\": 3,   \n",
    "              \"metric\": \"acc\", \n",
    "              \"mode\": \"min\",   \n",
    "              \"min_delta\": 0\n",
    "          })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Cycle Kek!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SomeFastaiFan: Did you stole something else from fastai?\n",
    "#\n",
    "# Me: Yes! One Cycle Policy!\n",
    "keker.kek_one_cycle(max_lr=1e-5,                  # the maximum learning rate\n",
    "                    cycle_len=5,                  # number of epochs, actually, but not exactly\n",
    "                    momentum_range=(0.95, 0.85),  # range of momentum changes\n",
    "                    div_factor=25,                # max_lr / min_lr\n",
    "                    increase_fraction=0.3)        # the part of cycle when learning rate increases\n",
    "\n",
    "# If you don't understand these parameters, read this - https://sgugger.github.io/the-1cycle-policy.html\n",
    "# NOTE: you cannot use schedulers and early stopping with one cycle!\n",
    "# another options are the same as for `kek` method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Keker features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freezing / unfreezing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We've already talk about freezing. But what if I want to unfreeze?\n",
    "# It has the same interface:\n",
    "keker.unfreeze(model_attr=\"net\")\n",
    "\n",
    "# If you want to freeze till some layer:\n",
    "layer_num = -2\n",
    "keker.freeze_to(layer_num, model_attr=\"net\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving / Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving\n",
    "keker.save(\"/path/to/file\")\n",
    "\n",
    "# loading\n",
    "keker.load(\"/path/to/file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device and DataParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keker is using all avialable GPUs by default\n",
    "# To limit it, use 'CUDA_VISIBLE_DEVICES' environment variable (available in os.environ dict)\n",
    "\n",
    "# if you want to specify cuda device for your model, specify `device` parameter on Keker initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are 4 (yes, four) ways to get a predictions with keker\n",
    "\n",
    "# 1st\n",
    "keker.predict(savepath=\"/path/to/save/dir\")\n",
    "# it will makes predicts on your 'test_dl' dataloader (remember, we initialized it with 'None'), if it specified,\n",
    "# and saves models output in numpy.ndarray format to 'savepath'\n",
    "\n",
    "# 2nd\n",
    "loader = val_dl\n",
    "keker.predict_loader(loader=loader, savepath=\"/path/to/save/dir\")\n",
    "# it will do the same as `predict()` but on any custom loader you want\n",
    "\n",
    "# 3rd\n",
    "tensor = torch.zeros(4, 224, 224, 3)\n",
    "preds = keker.predict_tensor(tensor=tensor, to_numpy=False)\n",
    "# it will return a predictions of the model in numpy format if `'to_numpy==True', else - torch.Tensor\n",
    "\n",
    "# 4th\n",
    "array = np.zeros((4, 224, 224, 3))\n",
    "preds = keker.predict_array(array=array, to_numpy=False)\n",
    "# it will do the same as `predict_tensor()` but with np.ndarra as input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am sure that it is not very convinient way for test time augmentations,\n",
    "# but here is how you can do it with Kekas\n",
    "\n",
    "# first, specify several augmentations for TTA\n",
    "flip_ = Flip(always_apply=True)\n",
    "vertical_flip_ = VerticalFlip(always_apply=True)\n",
    "transpose_ = Transpose(always_apply=True)\n",
    "\n",
    "# second, create the whole augmentations with theese ones inside\n",
    "def insert_aug(aug, dataset_key=\"image\", size=224):    \n",
    "    PRE_TFMS = Transformer(dataset_key, lambda x: cv2.resize(x, (size, size)))\n",
    "    \n",
    "    AUGS = Transformer(dataset_key, lambda x: aug(image=x)[\"image\"])\n",
    "    \n",
    "    NRM_TFMS = transforms.Compose([\n",
    "        Transformer(dataset_key, to_torch()),\n",
    "        Transformer(dataset_key, normalize())\n",
    "    ])\n",
    "    \n",
    "    tfm = transforms.Compose([PRE_TFMS, AUGS, NRM_TFMS])\n",
    "    return tfm\n",
    "\n",
    "\n",
    "flip = insert_aug(flip_)\n",
    "vertical_flip = insert_aug(vertical_flip_)\n",
    "transpose = insert_aug(transpose_)\n",
    "\n",
    "tta_tfms = {\"flip\": flip, \"v_flip\": vertical_flip, \"transpose\": transpose}\n",
    "\n",
    "# third, run TTA\n",
    "keker.TTA(loader=val_dl,                # loader to predict on \n",
    "          tfms=tta_tfms,                # list or dict of always applying transforms\n",
    "          savedir=\"/path/to/save/dir\",  # savedir\n",
    "          prefix=\"preds\")               # (optional) name prefix. default is 'preds'\n",
    "\n",
    "# it will saves predicts for each augmentation to savedir with name\n",
    "#  - {prefix}_{name_from_dict}.npy if tfms is a dict\n",
    "#  - {prefix}_{index}.npy          if tfms is a list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks is the way in which Kekas customizes its pipeline\n",
    "# each callback implements six methods, which names tell when it applies\n",
    "# on_train_begin()\n",
    "#     on_epoch_begin()\n",
    "#         on_batch_begin()\n",
    "#             >>>... step here ...<<<\n",
    "#         on_batch_end()\n",
    "#     on_epoch_end()\n",
    "# on_train_end()\n",
    "\n",
    "# Callbacks are widely using under the hood of Kekas\n",
    "# For example - loss, opimizer, progressbar, lr scheduling, checkpoint saving, early stopping etc\n",
    "# are realized as callbacks\n",
    "\n",
    "# Callback has access to `state` attr of a keker. Here is a docs from Keker about state:\n",
    "\n",
    "        # The state is an object that stores many variables and represents\n",
    "        # the state of your train-val-repdict pipeline. _state passed to every\n",
    "        # callback call.\n",
    "        # You can use it as a container for your custom variables, but\n",
    "        # DO NOT USE the following ones:\n",
    "        #\n",
    "        # loss, batch, model, dataowner, criterion, opt, parallel, checkpoint,\n",
    "        # stop_iter, stop_epoch, stop_train, out, sched, mode, loader, pbar,\n",
    "        # metrics, epoch_metrics\n",
    "\n",
    "# You can write your own callback, or use something useful from kekas.callbacks\n",
    "\n",
    "# Callbacks should be passes as a list at the Keker initiation\n",
    "# For example, let's use a DebuggerCallback, that just insert a pdb.set_trace() call in pipeline\n",
    "# For more info, please see a DebuggerCallback docs and source code\n",
    "debugger = DebuggerCallback(when=[\"on_epoch_begin\"], modes[\"train\"])\n",
    "\n",
    "keker = Keker(model=model, dataowner=dataowner, criterion=criterion, callbacks=[debugger])\n",
    "\n",
    "# also there is a method to add a callbacks to existing Keker\n",
    "\n",
    "keker.add_callbacks([debugger])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom loss and opimizer callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As was said, loss and optimezer behavior is realiesed as Callbacks.\n",
    "# If you use some tricky loss or optimizer logic, you can create your own Callback\n",
    "# and specify it during Keker initialization\n",
    "\n",
    "# here are the callbacks, that are using by default\n",
    "class LossCallback(Callback):\n",
    "    def __init__(self, target_key: str, preds_key: str) -> None:\n",
    "        # target_key and preds_key are the parameters of Keker\n",
    "        self.target_key = target_key\n",
    "        self.preds_key = preds_key\n",
    "\n",
    "    def on_batch_end(self, i: int, state: DotDict) -> None:\n",
    "        target = state.batch[self.target_key]\n",
    "        preds = state.out[self.preds_key]\n",
    "\n",
    "        state.loss = state.criterion(preds, target)\n",
    "\n",
    "class OptimizerCallback(Callback):\n",
    "    def on_batch_end(self, i: int, state: DotDict) -> None:\n",
    "        if state.mode == \"train\":\n",
    "            state.opt.zero_grad()\n",
    "            state.loss.backward()\n",
    "            state.opt.step()\n",
    "            \n",
    "# and here is how you should specify them during Keker initialization\n",
    "keker = Keker(model=model, \n",
    "              dataowner=dataowner,\n",
    "              criterion=criterion,\n",
    "              loss_cb=LossCallback,\n",
    "              opt_cb=OptimizerCallback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I hope you now got an idea how to use Kekas.\n",
    "\n",
    "I will be happy to get feedback about my library and this tutorial.\n",
    "\n",
    "You can find me in [OpenDataScience](http://ods.ai) community by @belskikh nikname or create an issue on GitHub.\n",
    "\n",
    "Have a good keks!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
