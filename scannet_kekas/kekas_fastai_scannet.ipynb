{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roma/.virtualenvs/aseg_torch1/lib/python3.6/site-packages/kekas/keker.py:9: UserWarning: Error 'No module named 'apex''' during importing apex library. To use mixed precison you should install it from https://github.com/NVIDIA/apex\n",
      "  warnings.warn(f\"Error '{e}'' during importing apex library. To use mixed precison\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "#import cv2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from pdb import set_trace as st\n",
    "\n",
    "#import pretrainedmodels as pm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "#from albumentations import Compose, JpegCompression, CLAHE, RandomRotate90, Transpose, ShiftScaleRotate, \\\n",
    "#        Blur, OpticalDistortion, GridDistortion, HueSaturationValue, Flip, VerticalFlip\n",
    "\n",
    "from kekas import Keker, DataOwner, DataKek\n",
    "from kekas.transformations import Transformer, to_torch, normalize\n",
    "from kekas.metrics import accuracy\n",
    "from kekas.modules import Flatten, AdaptiveConcatPool2d\n",
    "from kekas.callbacks import Callback, Callbacks, DebuggerCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai_sparse # 3D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparseconvnet as scn\n",
    "\n",
    "from fastai_sparse import utils, visualize\n",
    "from fastai_sparse.utils import log\n",
    "#from fastai_sparse.data import DataSourceConfig, MeshesDataset, SparseDataBunch\n",
    "#from fastai_sparse.learner import SparseModelConfig, Learner\n",
    "#from fastai_sparse.callbacks import TimeLogger, SaveModelCallback, CSVLogger\n",
    "from fastai_sparse.transforms import Transform, Compose\n",
    "\n",
    "from data import merge_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment environment and system metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import neptune\n",
    "#from neptune_callbacks import NeptuneMonitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_epoch': 384, 'max_lr': 2.0, 'wd': 0.0001}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params={'n_epoch': 384,\n",
    "        'max_lr': 2.0,\n",
    "        'wd':0.0001\n",
    "        }\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('NEPTUNE_API_TOKEN.txt','r') as f:\n",
    "#    NEPTUNE_API_TOKEN = f.readline().splitlines()[0]\n",
    "#    \n",
    "#neptune.init(api_token=NEPTUNE_API_TOKEN,\n",
    "#             project_qualified_name='roma-goodok/fastai-sparse-scannet')\n",
    "#\n",
    "## create experiment in the project defined above\n",
    "#exp = neptune.create_experiment(params=params)\n",
    "#print(exp.id)\n",
    "#exp.append_tag('study')\n",
    "#exp.append_tag('kekas')\n",
    "#exp.append_tag('unet24')\n",
    "#exp.append_tag('1cycle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: kekas_04\n",
      "Logdir: logdir/kekas_04\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    experiment_name = exp.id\n",
    "except Exception as e:\n",
    "    experiment_name = \"kekas_04\"\n",
    "\n",
    "print(\"Experiment:\", experiment_name)\n",
    "logdir = os.path.join('logdir', experiment_name)\n",
    "Path(logdir).mkdir(parents=True, exist_ok=True)\n",
    "print(\"Logdir:\", logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "virtualenv:     (aseg_torch1) \n",
      "python:         3.6.8\n",
      "nvidia driver:  b'384.130'\n",
      "nvidia cuda:    9.0, V9.0.176\n",
      "cudnn:          7.1.4\n",
      "torch:          1.0.0\n",
      "pandas:         0.24.2\n",
      "kekas:          0.1.17\n",
      "fastai:         1.0.48\n",
      "fastai_sparse:  0.0.4.dev0\n"
     ]
    }
   ],
   "source": [
    "utils.watermark(pandas=True, kekas=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m5502368\u001b[m mIoU callbacks implemented (draft)\r\n",
      "\u001b[33md5c7ab0\u001b[m kekas: train to reproduce FASSCN-23 :completed\r\n",
      "\u001b[33ma96a67d\u001b[m kekas: train to reproduce FASSCN-23 : in progress\r\n"
     ]
    }
   ],
   "source": [
    "!git log1 -n3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr 22 00:08:36 2019       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 384.130                Driver Version: 384.130                   |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:28:00.0  On |                  N/A |\r\n",
      "| 30%   58C    P2    67W / 250W |   7010MiB / 11163MiB |      1%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:29:00.0 Off |                  N/A |\r\n",
      "|  0%   53C    P2    54W / 250W |     11MiB / 11172MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0      1428      G   /usr/lib/xorg/Xorg                           543MiB |\r\n",
      "|    0      2803      G   compiz                                       287MiB |\r\n",
      "|    0      3159      G   /usr/lib/firefox/firefox                     614MiB |\r\n",
      "|    0      4548      G   ...-token=984E0E17258E906521CB9B221D39B059   105MiB |\r\n",
      "|    0     11199      C   ...oma/.virtualenvs/aseg_torch1/bin/python  5455MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name:            AMD Ryzen 7 1700 Eight-Core Processor\r\n"
     ]
    }
   ],
   "source": [
    "!lscpu | grep \"Model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter notebook display options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:70% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "utils.wide_notebook()\n",
    "# uncomment this lines if you want switch off interactive and save visaulisation as screenshoots:\n",
    "# For rendering run command in terminal:    `chromium-browser --remote-debugging-port=9222`\n",
    "if False:\n",
    "    visualize.options.interactive = False\n",
    "    visualize.options.save_images = True\n",
    "    visualize.options.verbose = True\n",
    "    visualize.options.filename_pattern_image = Path('images', experiment_name, 'fig_{fig_number}')\n",
    "else:\n",
    "    for key, o in visualize.options.__dataclass_fields__.items():\n",
    "        setattr(visualize.options, key, o.default)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see how download and preprocess data by the following link from fastai_sparse library: https://github.com/goodok/fastai_sparse/tree/master/examples/scannet/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scene0000_01.merged.ply']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SOURCE_DIR = Path('data', 'scannet_merged_ply')\n",
    "assert SOURCE_DIR.exists(), \"Run prepare_data.ipynb\"\n",
    "\n",
    "definition_of_spliting_dir = Path('data', 'ScanNet_Tasks_Benchmark')\n",
    "assert definition_of_spliting_dir.exists()\n",
    "\n",
    "\n",
    "os.listdir(SOURCE_DIR / 'scene0000_01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_files(path, ext='merged.ply'):\n",
    "    pattern = str(path / '*' / ('*' + ext))\n",
    "    fnames = glob.glob(pattern)\n",
    "    return fnames\n",
    "\n",
    "def get_df_list(verbose=0):\n",
    "    # train /valid / test splits\n",
    "    fn_lists = {}\n",
    "\n",
    "    fn_lists['train'] = definition_of_spliting_dir / 'scannetv1_train.txt'\n",
    "    fn_lists['valid'] = definition_of_spliting_dir / 'scannetv1_val.txt'\n",
    "    fn_lists['test'] = definition_of_spliting_dir / 'scannetv1_test.txt'\n",
    "\n",
    "    for datatype in ['train', 'valid', 'test']:\n",
    "        assert fn_lists[datatype].exists(), datatype\n",
    "\n",
    "    dfs = {}\n",
    "    total = 0\n",
    "    for datatype in ['train', 'valid', 'test']:\n",
    "        df = pd.read_csv(fn_lists[datatype], header=None, names=['example_id'])\n",
    "        df = df.assign(datatype=datatype)\n",
    "        df = df.assign(subdir=df.example_id)\n",
    "        df = df.sort_values('example_id')\n",
    "        dfs[datatype] = df\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"{datatype:5} counts: {len(df):>4}\")\n",
    "        \n",
    "        total += len(df)\n",
    "    if verbose:\n",
    "        print(f\"total:     {total}\")\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train counts: 1045\n",
      "valid counts:  156\n",
      "test  counts:  312\n",
      "total:     1513\n"
     ]
    }
   ],
   "source": [
    "df_list = get_df_list(verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>datatype</th>\n",
       "      <th>subdir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>scene0000_00</td>\n",
       "      <td>train</td>\n",
       "      <td>scene0000_00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>scene0000_01</td>\n",
       "      <td>train</td>\n",
       "      <td>scene0000_01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>scene0000_02</td>\n",
       "      <td>train</td>\n",
       "      <td>scene0000_02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>scene0001_00</td>\n",
       "      <td>train</td>\n",
       "      <td>scene0001_00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>scene0001_01</td>\n",
       "      <td>train</td>\n",
       "      <td>scene0001_01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       example_id datatype        subdir\n",
       "827  scene0000_00    train  scene0000_00\n",
       "828  scene0000_01    train  scene0000_01\n",
       "829  scene0000_02    train  scene0000_02\n",
       "496  scene0001_00    train  scene0001_00\n",
       "497  scene0001_01    train  scene0001_01"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list['train'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scene0000_00.merged.ply']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(os.path.join(SOURCE_DIR, 'scene0000_00'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai_sparse.data_items  import MeshItem, PointsItem\n",
    "from fastai_sparse.learner import SparseModelConfig\n",
    "import transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at first we need to create a reader function that will define how image will be opened\n",
    "def reader_fn(i, row):\n",
    "    fn = SOURCE_DIR / row['subdir'] / f'{row[\"example_id\"]}.merged.ply'\n",
    "    m = MeshItem.from_file(fn, label_field='label')\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MeshItem (scene0000_00.merged.ply)\n",
      "vertices:                shape: (81369, 3)            dtype: float64        min:   -0.01657,  max:    8.74040,  mean:    3.19051\n",
      "faces:                   shape: (153587, 3)           dtype: int64          min:          0,  max:      81368,  mean: 40549.68796\n",
      "colors:                  shape: (81369, 4)            dtype: uint8          min:    1.00000,  max:  255.00000,  mean:  145.80430\n",
      "labels:                  shape: (81369,)              dtype: uint16         min:    0.00000,  max:  230.00000,  mean:   12.97057\n",
      "Colors from vertices\n",
      "Labels from vertices\n"
     ]
    }
   ],
   "source": [
    "m = reader_fn(0, df_list['train'].iloc[0])\n",
    "m.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map relevant classes to {0,1,...,19}, and ignored classes to -100\n",
    "remapper = np.ones(3000, dtype=np.int32) * (-100)\n",
    "for i, x in enumerate([1,2,3,4,5,6,7,8,9,10,11,12,14,16,24,28,33,34,36,39]):\n",
    "    remapper[x] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_TFMS = [T.to_points_cloud(method='vertices', normals=False), \n",
    "            T.remap_labels(remapper=remapper, inplace=False),\n",
    "            T.colors_normalize(),\n",
    "            T.normalize_spatial(),\n",
    "           ]\n",
    "\n",
    "_scale = 20\n",
    "\n",
    "AUGS_TRAIN = [\n",
    "    T.noise_affine(amplitude=0.1),\n",
    "    T.flip_x(p=0.5),\n",
    "    T.scale(scale=_scale),\n",
    "    T.rotate_XY(),\n",
    "    \n",
    "    T.elastic(gran=6 * _scale // 50, mag=40 * _scale / 50),\n",
    "    T.elastic(gran=20 * _scale // 50, mag=160 * _scale / 50),\n",
    "    \n",
    "    T.specific_translate(full_scale=4096),\n",
    "    T.crop_points(low=0, high=4096),\n",
    "    T.colors_noise(amplitude=0.1),\n",
    "]\n",
    "\n",
    "AUGS_VALID = [\n",
    "    T.noise_affine(amplitude=0.1),\n",
    "    T.flip_x(p=0.5),\n",
    "    T.scale(scale=_scale),\n",
    "    T.rotate_XY(),\n",
    "\n",
    "    T.translate(offset=4096 / 2),\n",
    "    T.rand_translate(offset=(-2, 2, 3)),  # low, high, dimention\n",
    "    \n",
    "    T.specific_translate(full_scale=4096),\n",
    "    T.crop_points(low=0, high=4096),\n",
    "    T.colors_noise(amplitude=0.1),\n",
    "        \n",
    "    ]\n",
    "\n",
    "SPARSE_TFMS = [\n",
    "    T.merge_features(ones=False, colors=True, normals=False),\n",
    "    T.to_sparse_voxels(),\n",
    "]\n",
    "\n",
    "\n",
    "# reimplement to_torch\n",
    "def _to_torch(x):\n",
    "    x.coords \n",
    "    x.features\n",
    "    x.labels\n",
    "    \n",
    "    return x\n",
    "\n",
    "# to_torch = Transform(_to_torch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "functools.partial(<function SparseDataBunch.merge_fn at 0x7fc6be575400>, keys_lists=['id', 'labels_raw', 'filtred_mask', 'random_seed', 'num_points'], separate_labels=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data import merge_fn\n",
    "merge_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(dataset_key):\n",
    "        \n",
    "    return  Compose(PRE_TFMS + AUGS_TRAIN + SPARSE_TFMS), Compose(PRE_TFMS + AUGS_VALID + SPARSE_TFMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataKeks creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df_list['train']#.head(96)\n",
    "val_df = df_list['valid']#.head(96)\n",
    "\n",
    "# now let's create DataKeks\n",
    "train_tfms, val_tfms = get_transforms(\"mesh\")\n",
    "\n",
    "train_dk = DataKek(df=train_df, reader_fn=reader_fn, transforms=train_tfms)\n",
    "val_dk = DataKek(df=val_df, reader_fn=reader_fn, transforms=val_tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: scene0000_00.merged\n",
      "coords                   shape: (81369, 3)            dtype: int64          min:       2537,  max:       3649,  mean: 3089.22016\n",
      "features                 shape: (81369, 3)            dtype: float32        min:   -1.17197,  max:    1.11335,  mean:   -0.16876\n",
      "x                        shape: (81369,)              dtype: int64          min:       3044,  max:       3235,  mean: 3140.09126\n",
      "y                        shape: (81369,)              dtype: int64          min:       3474,  max:       3649,  mean: 3552.26375\n",
      "z                        shape: (81369,)              dtype: int64          min:       2537,  max:       2641,  mean: 2575.30547\n",
      "labels                   shape: (81369,)              dtype: int64          min:       -100,  max:         17,  mean:  -48.51506\n",
      "voxels: 54416\n",
      "points / voxels: 1.4953138782710966\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c66512b365f548778c553474c053dc73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "b = train_dk[0]\n",
    "b.describe()\n",
    "b.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and DataLoaders\n",
    "#batch_size = 32\n",
    "#workers = \n",
    "\n",
    "train_dl = DataLoader(train_dk, batch_size=32, num_workers=8, shuffle=True, drop_last=True, collate_fn=merge_fn, pin_memory=False)\n",
    "val_dl = DataLoader(val_dk, batch_size=2, num_workers=2, shuffle=False, collate_fn=merge_fn, pin_memory=False)\n",
    "\n",
    "#train_dl = DataLoader(train_dk, batch_size=12, num_workers=8, shuffle=True, drop_last=True, collate_fn=merge_fn, pin_memory=False)\n",
    "#val_dl = DataLoader(val_dk, batch_size=2, num_workers=2, shuffle=False, collate_fn=merge_fn, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dl.pin_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dl.pin_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "for i, batch in enumerate(train_dl):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'coords': tensor([[3103, 1525, 1590,    0],\n",
       "         [3103, 1525, 1591,    0],\n",
       "         [3103, 1526, 1591,    0],\n",
       "         ...,\n",
       "         [  44, 3057, 3422,   31],\n",
       "         [  44, 3057, 3422,   31],\n",
       "         [  44, 3057, 3422,   31]]),\n",
       " 'features': tensor([[-0.0393, -0.1166, -0.2235],\n",
       "         [-0.0549, -0.1323, -0.2549],\n",
       "         [-0.0706, -0.1479, -0.3020],\n",
       "         ...,\n",
       "         [-0.4921, -0.5751, -0.4440],\n",
       "         [-0.4999, -0.5751, -0.4597],\n",
       "         [-0.2411, -0.3242, -0.1930]]),\n",
       " 'labels': tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       " 'id': ['scene0470_00.merged',\n",
       "  'scene0662_00.merged',\n",
       "  'scene0235_00.merged',\n",
       "  'scene0654_01.merged',\n",
       "  'scene0576_02.merged',\n",
       "  'scene0368_00.merged',\n",
       "  'scene0360_00.merged',\n",
       "  'scene0099_01.merged',\n",
       "  'scene0254_00.merged',\n",
       "  'scene0031_01.merged',\n",
       "  'scene0511_01.merged',\n",
       "  'scene0150_01.merged',\n",
       "  'scene0121_02.merged',\n",
       "  'scene0501_01.merged',\n",
       "  'scene0128_00.merged',\n",
       "  'scene0369_02.merged',\n",
       "  'scene0649_00.merged',\n",
       "  'scene0569_00.merged',\n",
       "  'scene0449_02.merged',\n",
       "  'scene0673_00.merged',\n",
       "  'scene0380_01.merged',\n",
       "  'scene0302_00.merged',\n",
       "  'scene0199_00.merged',\n",
       "  'scene0601_00.merged',\n",
       "  'scene0399_01.merged',\n",
       "  'scene0444_00.merged',\n",
       "  'scene0029_01.merged',\n",
       "  'scene0348_01.merged',\n",
       "  'scene0563_00.merged',\n",
       "  'scene0166_00.merged',\n",
       "  'scene0210_00.merged',\n",
       "  'scene0582_01.merged'],\n",
       " 'labels_raw': [array([0, 0, 0, 0, ..., 0, 4, 4, 4], dtype=int32),\n",
       "  array([-100, -100, -100, -100, ...,    0,    0,    0, -100], dtype=int32),\n",
       "  array([-100, -100, -100, -100, ..., -100, -100, -100, -100], dtype=int32),\n",
       "  array([-100, -100, -100, -100, ..., -100, -100, -100, -100], dtype=int32),\n",
       "  array([  17, -100, -100, -100, ..., -100, -100, -100, -100], dtype=int32),\n",
       "  array([1, 1, 1, 1, ..., 0, 0, 0, 0], dtype=int32),\n",
       "  array([0, 0, 2, 0, ..., 0, 0, 0, 0], dtype=int32),\n",
       "  array([   0,    0,    0,    0, ..., -100, -100, -100, -100], dtype=int32),\n",
       "  array([0, 0, 0, 0, ..., 0, 0, 0, 0], dtype=int32),\n",
       "  array([   2,    2,    2,    2, ..., -100, -100, -100, -100], dtype=int32),\n",
       "  array([-100, -100, -100, -100, ..., -100, -100, -100, -100], dtype=int32),\n",
       "  array([-100, -100,    2,    2, ...,    0,    0,    0,    0], dtype=int32),\n",
       "  array([-100, -100, -100, -100, ..., -100, -100, -100, -100], dtype=int32),\n",
       "  array([-100, -100, -100, -100, ..., -100, -100, -100, -100], dtype=int32),\n",
       "  array([   2,    2,    2,    2, ..., -100, -100, -100, -100], dtype=int32),\n",
       "  array([2, 2, 2, 2, ..., 0, 0, 0, 0], dtype=int32),\n",
       "  array([-100, -100, -100, -100, ...,    0,    0,    0, -100], dtype=int32),\n",
       "  array([-100, -100, -100, -100, ...,    0,    0,    0,    0], dtype=int32),\n",
       "  array([-100, -100, -100, -100, ..., -100, -100, -100, -100], dtype=int32),\n",
       "  array([-100, -100, -100, -100, ..., -100,    0,    0,    0], dtype=int32),\n",
       "  array([-100, -100, -100, -100, ..., -100, -100, -100, -100], dtype=int32),\n",
       "  array([2, 2, 2, 2, ..., 0, 0, 0, 0], dtype=int32),\n",
       "  array([2, 2, 2, 2, ..., 0, 0, 0, 0], dtype=int32),\n",
       "  array([-100, -100, -100, -100, ...,    0,    0,    0,    0], dtype=int32),\n",
       "  array([-100, -100, -100, -100, ...,    2,    2,    2,    2], dtype=int32),\n",
       "  array([6, 6, 6, 6, ..., 0, 0, 0, 0], dtype=int32),\n",
       "  array([-100, -100, -100, -100, ..., -100,    0,    0,    0], dtype=int32),\n",
       "  array([-100, -100, -100, -100, ...,    0,    0,    0,    0], dtype=int32),\n",
       "  array([-100, -100, -100, -100, ..., -100, -100, -100, -100], dtype=int32),\n",
       "  array([   2, -100, -100, -100, ..., -100, -100,    0,    0], dtype=int32),\n",
       "  array([0, 0, 6, 6, ..., 2, 2, 2, 2], dtype=int32),\n",
       "  array([7, 7, 7, 7, ..., 0, 0, 0, 0], dtype=int32)],\n",
       " 'filtred_mask': [array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True])],\n",
       " 'random_seed': ['182479695_340',\n",
       "  '1292740222_264',\n",
       "  '1741434149_312',\n",
       "  '2823988168_140',\n",
       "  '649861767_228',\n",
       "  '2941211774_112',\n",
       "  '3379533227_440',\n",
       "  '296525474_80',\n",
       "  '207020725_440',\n",
       "  '497598068_40',\n",
       "  '3168221195_300',\n",
       "  '2881255566_336',\n",
       "  '806421572_224',\n",
       "  '1119037316_116',\n",
       "  '2052385399_276',\n",
       "  '1697349261_388',\n",
       "  '3481073715_56',\n",
       "  '225097249_100',\n",
       "  '157631320_492',\n",
       "  '100342_396',\n",
       "  '1848795919_364',\n",
       "  '2102817586_576',\n",
       "  '2361204992_576',\n",
       "  '3008858478_444',\n",
       "  '2221092942_92',\n",
       "  '3021209329_532',\n",
       "  '1617108327_108',\n",
       "  '3246590741_108',\n",
       "  '1593665656_304',\n",
       "  '3184915984_348',\n",
       "  '598897525_52',\n",
       "  '940621256_364'],\n",
       " 'num_points': [67465,\n",
       "  46821,\n",
       "  191926,\n",
       "  187822,\n",
       "  130258,\n",
       "  100591,\n",
       "  81298,\n",
       "  170918,\n",
       "  119777,\n",
       "  235122,\n",
       "  83484,\n",
       "  77935,\n",
       "  98699,\n",
       "  111898,\n",
       "  108008,\n",
       "  153044,\n",
       "  70554,\n",
       "  142057,\n",
       "  59822,\n",
       "  254321,\n",
       "  164540,\n",
       "  292241,\n",
       "  170183,\n",
       "  209655,\n",
       "  84554,\n",
       "  25481,\n",
       "  41212,\n",
       "  71272,\n",
       "  129766,\n",
       "  225624,\n",
       "  114103,\n",
       "  166400]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4186851, 4186851)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch['coords']), sum(batch['num_points'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseModelConfig;\n",
       "   spatial_size: 4096\n",
       "   dimension: 3\n",
       "   block_reps: 1\n",
       "   m: 16\n",
       "   num_planes: [16, 32, 48, 64, 80, 96, 112]\n",
       "   residual_blocks: False\n",
       "   num_classes: 20\n",
       "   num_input_features: 3\n",
       "   mode: 4\n",
       "   downsample: [2, 2]\n",
       "   bias: False"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spatial_size  is full_scale\n",
    "model_config = SparseModelConfig(spatial_size=4096, num_classes=20, num_input_features=3, mode=4,\n",
    "                                 m=16, num_planes_coeffs=[1, 2, 3, 4, 5, 6, 7])\n",
    "model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        C = cfg\n",
    "        nn.Module.__init__(self)\n",
    "        self.sparseModel = scn.Sequential(\n",
    "            scn.InputLayer(C.dimension, C.spatial_size, mode=C.mode),\n",
    "            scn.SubmanifoldConvolution(C.dimension, nIn=C.num_input_features, nOut=C.m, filter_size=3, bias=C.bias),\n",
    "            scn.UNet(C.dimension, C.block_reps, C.num_planes, residual_blocks=C.residual_blocks, downsample=C.downsample),\n",
    "            scn.BatchNormReLU(C.m),\n",
    "            scn.OutputLayer(C.dimension),\n",
    "        )\n",
    "        self.linear = nn.Linear(C.m, C.num_classes)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        x = [xb['coords'], xb['features']]\n",
    "        x = self.sparseModel(x)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "model = Model(model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the three whales of your pipelane are: the data, the model and the loss (hi, Jeremy)\n",
    "\n",
    "# the data is represented in Kekas by DataOwner. It is a namedtuple with three fields:\n",
    "# 'train_dl', 'val_dl', 'test_dl'\n",
    "# For training process we will need at least two of them, and we can skip 'test_dl' for now\n",
    "# so we will initialize it with `None` value.\n",
    "dataowner = DataOwner(train_dl, val_dl, None)\n",
    "\n",
    "# model is just a pytorch nn.Module, that we created vefore\n",
    "#model = Net(num_classes=2)\n",
    "\n",
    "# loss or criterion is also a pytorch nn.Module. For multiloss scenarios it can be a list of nn.Modules\n",
    "# for our simple example let's use the standart cross entopy criterion\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also we need to specify, what model will do with each batch of data on each iteration\n",
    "# We should define a `step_fn` function\n",
    "# The code below repeats a `keker.default_step_fn` code to provide you with a concept of step function\n",
    "\n",
    "def step_fn(model: torch.nn.Module,\n",
    "            batch: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Determine what your model will do with your data.\n",
    "\n",
    "    Args:\n",
    "        model: the pytorch module to pass input in\n",
    "        batch: the batch of data from the DataLoader\n",
    "\n",
    "    Returns:\n",
    "        The models forward pass results\n",
    "    \"\"\"\n",
    "    \n",
    "    # you could define here whatever logic you want\n",
    "    inp = batch  # here we get an \"image\" from our dataset\n",
    "    return model(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "from fastai.torch_core import add_metrics\n",
    "from fastai_sparse.metrics import confusion_matrix, iou_per_class_from_cm\n",
    "\n",
    "from collections import defaultdict\n",
    "from kekas.utils import get_opt_lr, get_pbar, DotDict, to_numpy\n",
    "\n",
    "\n",
    "class IouMeanFiltred(Callback):\n",
    "    \"\"\"\n",
    "    Calc IoU by classes, filter incorrect classes (-100), then mean.\n",
    "    \"\"\"\n",
    "\n",
    "    _order = -19  # Needs to run before the recorder\n",
    "\n",
    "    def __init__(self, target_key: str, preds_key: str, n_classes, name='iouf', epsilon=sys.float_info.epsilon, **kwargs):\n",
    "        self.target_key = target_key\n",
    "        self.preds_key = preds_key\n",
    "        self.n_classes = n_classes\n",
    "        self.epsilon = epsilon\n",
    "        self.name = name\n",
    "        \n",
    "        # for kekas\n",
    "        self.pbar_metrics = None\n",
    "\n",
    "        #super().__init__(learn, **kwargs)\n",
    "\n",
    "    #def append_metrics_names(self, names):\n",
    "    #    recorder = self.learn.recorder\n",
    "    #    if not hasattr(recorder, '_added_met_names'):\n",
    "    #        recorder._added_met_names = []\n",
    "    #    recorder._added_met_names += names\n",
    "\n",
    "    #def on_train_begin(self, **kwargs):\n",
    "    #    #self.append_metrics_names(self.names)\n",
    "        \n",
    "\n",
    "    #def on_epoch_begin(self, **kwargs):\n",
    "    def on_epoch_begin(self, epoch: int, epochs: int, state: DotDict) -> None:\n",
    "        \n",
    "        #print(\"state.core.mode:\", state.core.mode)\n",
    "        self._d = {}\n",
    "\n",
    "        d = {}\n",
    "        if state.core.mode == 'train':\n",
    "            self._d['train'] = d\n",
    "        elif state.core.mode == 'val':\n",
    "            self._d['valid'] = d\n",
    "\n",
    "        if state.core.mode in ['train', 'val']:\n",
    "            d['runned'] = False\n",
    "            d['cm'] = np.zeros(shape=(self.n_classes, self.n_classes), dtype=np.uint64)\n",
    "            \n",
    "        # for kekas\n",
    "        self.pbar_metrics = defaultdict(float)\n",
    "\n",
    "    #def on_batch_end(self, last_output, last_target, last_input, train, **kwargs):\n",
    "    def on_batch_end(self, i: int, state: DotDict) -> None:\n",
    "        \n",
    "        train = (state.core.mode == 'train')\n",
    "        \n",
    "        #print(\"state.core.mode:\", state.core.mode)\n",
    "        #print(\"state.core.do_log:\", state.core.do_log)\n",
    "\n",
    "        last_target = state.core.batch[self.target_key]\n",
    "        last_input = state.core.batch\n",
    "        last_output = state.core.out[self.preds_key]\n",
    "\n",
    "        if train:\n",
    "            d = self._d['train']\n",
    "        else:\n",
    "            d = self._d['valid']\n",
    "\n",
    "        #predictions = last_output.detach().cpu().numpy()\n",
    "        predictions = last_output\n",
    "       \n",
    "        \n",
    "        xb = last_input\n",
    "\n",
    "        num_points_actual_cumsum = np.cumsum([0] + xb['num_points'])\n",
    "        \n",
    "        cm_batch = np.zeros(shape=(self.n_classes, self.n_classes), dtype=np.uint64)\n",
    "\n",
    "        # for each example in the batch extract prediction, argmax, fill omitted by 0-label class (bug), and store\n",
    "        for k in range(len(xb['id'])):\n",
    "            # actual number of points\n",
    "            # num_points = xb['num_points'][k]     # equal len(y)\n",
    "\n",
    "            labels_raw = xb['labels_raw'][k]\n",
    "            filtred_mask = xb['filtred_mask'][k]\n",
    "            num_points_raw = len(labels_raw)\n",
    "\n",
    "            # extract prediction of example\n",
    "            start = num_points_actual_cumsum[k]\n",
    "            end = num_points_actual_cumsum[k + 1]\n",
    "            example_preds_actual = predictions[start:end]\n",
    "\n",
    "            # Use argmax now\n",
    "            # form target prediction\n",
    "            example_y_pred = np.ones(shape=(num_points_raw), dtype=np.int32) * (self.n_classes - 1)\n",
    "\n",
    "            # fill preds for the points that net outputs, eg 800, than 200 will be remains with zeros\n",
    "            example_y_pred[filtred_mask] = example_preds_actual.argmax(1)\n",
    "\n",
    "            # filter\n",
    "            indexer = labels_raw >= 0\n",
    "\n",
    "            # accumulate cm of example\n",
    "            y_pred = example_y_pred[indexer]\n",
    "            y_true = labels_raw[indexer]\n",
    "            if len(y_pred) == 0:\n",
    "                warnings.warn(f\"Wrong example is found: all `labels_raw` < 0. Id={xb['id'][k]}\")\n",
    "            else:\n",
    "                cm = confusion_matrix(y_pred, y_true, self.n_classes)\n",
    "                #d['cm'] += cm\n",
    "                cm_batch += cm\n",
    "                d['runned'] = True\n",
    "                \n",
    "        d['cm'] += cm_batch\n",
    "        #_iou_per_class = iou_per_class_from_cm(cm_batch)\n",
    "        #_iou = np.mean(_iou_per_class)\n",
    "\n",
    "        #print(state.core.mode, _iou, len(xb['id']))\n",
    "                              \n",
    "        #if state.core.mode == \"val\":            \n",
    "        #    self.pbar_metrics[self.name] = _iou\n",
    "\n",
    "        #if state.core.mode != \"test\" and state.core.do_log:\n",
    "        ## state.core.metrics[state.core.mode][\"loss\"] = float(to_numpy(state.core.loss))\n",
    "        #    state.core.metrics[state.core.mode][self.name] = _iou\n",
    "      \n",
    "\n",
    "    #def on_epoch_end(self, last_metrics, **kwargs):\n",
    "    def on_epoch_end(self, epoch: int, state: DotDict) -> None:\n",
    "\n",
    "        #print(\"on_epoch_end: state.core.mode:\", state.core.mode)\n",
    "                              \n",
    "        d = None\n",
    "        if state.core.mode == 'train':\n",
    "            d = self._d['train']\n",
    "        elif state.core.mode == 'val':\n",
    "            d = self._d['valid']\n",
    "\n",
    "        if d is not None:\n",
    "            if d['runned']:\n",
    "                cm = d['cm']\n",
    "                d['iou_per_class'] = iou_per_class_from_cm(cm)\n",
    "                d['iou'] = np.mean(d['iou_per_class'])\n",
    "            else:\n",
    "                d['cm'] = None\n",
    "                d['iou_per_class'] = None\n",
    "                d['iou'] = 0\n",
    "                                      \n",
    "            self.pbar_metrics[state.core.mode + \"_\" + self.name] = d['iou']\n",
    "\n",
    "            if state.core.epoch_metrics is None:\n",
    "                  state.core.epoch_metrics = self.pbar_metrics.copy()\n",
    "            else:\n",
    "                state.core.epoch_metrics.update(self.pbar_metrics)\n",
    "            #print(state.core.epoch_metrics)\n",
    "\n",
    "        \n",
    "                              \n",
    "                              \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keker_callbacks = []\n",
    "keker_callbacks.append(IouMeanFiltred(target_key='labels', preds_key='preds', n_classes=model_config.num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# previous preparations was mostly out of scope of Kekas library (except DataKeks creation)\n",
    "# Now let's dive into kekas a little bit\n",
    "\n",
    "# firstly, we create a Keker - the core Kekas class, that provides all the keks for your pipeline\n",
    "keker = Keker(model=model,\n",
    "              dataowner=dataowner,\n",
    "              criterion=criterion,\n",
    "              step_fn=step_fn,                    # previosly defined step function\n",
    "              target_key=\"labels\",                # remember, we defined it in the reader_fn for DataKek?              \n",
    "              opt=torch.optim.SGD,                # optimizer class. if note specifiyng, \n",
    "                                                  # an SGD is using by default\n",
    "              opt_params={\"weight_decay\": params['wd']},  # optimizer kwargs in dict format (optional too)\n",
    "              callbacks=keker_callbacks\n",
    "             )\n",
    "\n",
    "# Actually, there are a lot of params for kekers, but this out of scope of this example\n",
    "# you can read about them in Keker's docstring (but who really reads the docs, huh?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before the start of the finetuning procedure let's freeeze all the layers except the last one - the head\n",
    "# the `freeze` method is mostly inspired (or stolen) from fastai\n",
    "# but you should define a model's attribute to deal with\n",
    "# for example, our model is actually model.net, so we need to specify the 'net' attr\n",
    "# also this method does not freezes batchnorm layers by default. To change this set `freeze_bn=True`\n",
    "\n",
    "#keker.freeze(model_attr=\"net\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 78)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataowner.train_dl), len(dataowner.val_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate Find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100% 32/32 [03:09<00:00,  4.23s/it, loss=2.4019]\n",
      "End of LRFinder\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let's find an 'optimal' learning rate with learning rate find procedure\n",
    "# for details please see the fastai course and this articles:\n",
    "# https://arxiv.org/abs/1803.09820\n",
    "# https://sgugger.github.io/how-do-you-find-a-good-learning-rate.html\n",
    "\n",
    "# NOTE: this is an optional step and you can skip it and use your favorite learning rate\n",
    "\n",
    "# you MUST specify the logdir to see graphics\n",
    "# keker will write a tensorboard logs into this folder\n",
    "# to see them start a tensorboard with `--logdir /path/to/logdir`\n",
    "# OR you can use keker.plot_kek_lr method (see cell below)\n",
    "keker.kek_lr(final_lr=0.1, logdir=\"logdir_lr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "name": "train/batch/loss",
         "type": "scatter",
         "uid": "3cfc8c95-69f0-48f7-9865-3696748d940c",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31
         ],
         "y": [
          3.1508469581604004,
          3.155036687850952,
          3.1586554050445557,
          3.1575560569763184,
          3.15378999710083,
          3.157327651977539,
          3.1372246742248535,
          3.147700309753418,
          3.154764175415039,
          3.154165029525757,
          3.164154291152954,
          3.139570951461792,
          3.1136326789855957,
          3.153083562850952,
          3.1389577388763428,
          3.1245481967926025,
          3.1077356338500977,
          3.121633529663086,
          3.0495405197143555,
          2.961421489715576,
          2.9264042377471924,
          2.8268916606903076,
          2.728623867034912,
          2.633754014968872,
          2.5442726612091064,
          2.4414467811584473,
          2.356302261352539,
          2.1476333141326904,
          1.9068760871887207,
          1.7697784900665283,
          1.7481977939605713,
          1.418802261352539
         ]
        }
       ],
       "layout": {
        "title": {
         "text": "batch/loss"
        },
        "yaxis": {
         "hoverformat": ".6f"
        }
       }
      },
      "text/html": [
       "<div id=\"a5aa72f6-c5bf-4b32-91db-68b25e6dfb22\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"a5aa72f6-c5bf-4b32-91db-68b25e6dfb22\")) {\n",
       "    Plotly.newPlot(\"a5aa72f6-c5bf-4b32-91db-68b25e6dfb22\", [{\"name\": \"train/batch/loss\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], \"y\": [3.1508469581604004, 3.155036687850952, 3.1586554050445557, 3.1575560569763184, 3.15378999710083, 3.157327651977539, 3.1372246742248535, 3.147700309753418, 3.154764175415039, 3.154165029525757, 3.164154291152954, 3.139570951461792, 3.1136326789855957, 3.153083562850952, 3.1389577388763428, 3.1245481967926025, 3.1077356338500977, 3.121633529663086, 3.0495405197143555, 2.961421489715576, 2.9264042377471924, 2.8268916606903076, 2.728623867034912, 2.633754014968872, 2.5442726612091064, 2.4414467811584473, 2.356302261352539, 2.1476333141326904, 1.9068760871887207, 1.7697784900665283, 1.7481977939605713, 1.418802261352539], \"type\": \"scatter\", \"uid\": \"3cfc8c95-69f0-48f7-9865-3696748d940c\"}], {\"title\": {\"text\": \"batch/loss\"}, \"yaxis\": {\"hoverformat\": \".6f\"}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"a5aa72f6-c5bf-4b32-91db-68b25e6dfb22\")) {window._Plotly.Plots.resize(document.getElementById(\"a5aa72f6-c5bf-4b32-91db-68b25e6dfb22\"));};})</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"a5aa72f6-c5bf-4b32-91db-68b25e6dfb22\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"a5aa72f6-c5bf-4b32-91db-68b25e6dfb22\")) {\n",
       "    Plotly.newPlot(\"a5aa72f6-c5bf-4b32-91db-68b25e6dfb22\", [{\"name\": \"train/batch/loss\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], \"y\": [3.1508469581604004, 3.155036687850952, 3.1586554050445557, 3.1575560569763184, 3.15378999710083, 3.157327651977539, 3.1372246742248535, 3.147700309753418, 3.154764175415039, 3.154165029525757, 3.164154291152954, 3.139570951461792, 3.1136326789855957, 3.153083562850952, 3.1389577388763428, 3.1245481967926025, 3.1077356338500977, 3.121633529663086, 3.0495405197143555, 2.961421489715576, 2.9264042377471924, 2.8268916606903076, 2.728623867034912, 2.633754014968872, 2.5442726612091064, 2.4414467811584473, 2.356302261352539, 2.1476333141326904, 1.9068760871887207, 1.7697784900665283, 1.7481977939605713, 1.418802261352539], \"type\": \"scatter\", \"uid\": \"3cfc8c95-69f0-48f7-9865-3696748d940c\"}], {\"title\": {\"text\": \"batch/loss\"}, \"yaxis\": {\"hoverformat\": \".6f\"}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"a5aa72f6-c5bf-4b32-91db-68b25e6dfb22\")) {window._Plotly.Plots.resize(document.getElementById(\"a5aa72f6-c5bf-4b32-91db-68b25e6dfb22\"));};})</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "name": "train/batch/lr",
         "type": "scatter",
         "uid": "a42398fb-047c-41dd-821f-cf43a25d134e",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31
         ],
         "y": [
          9.999999974752427e-07,
          1.4497406937152846e-06,
          2.1017481230956037e-06,
          3.046989604627015e-06,
          4.417344825924374e-06,
          6.404004125215579e-06,
          9.284145562560298e-06,
          1.3459602996590547e-05,
          1.951293415913824e-05,
          2.8288694011280313e-05,
          4.101126978639513e-05,
          5.945570592302829e-05,
          8.619535947218537e-05,
          0.00012496091949287802,
          0.0001811609254218638,
          0.0002626363420858979,
          0.0003807546163443476,
          0.0005519954138435423,
          0.0008002502145245671,
          0.0011601552832871675,
          0.00168192433193326,
          0.0024383540730923414,
          0.0035349810495972633,
          0.005124805960804224,
          0.007429639343172312,
          0.010771050117909908,
          0.015615230426192284,
          0.02263803407549858,
          0.03281927853822708,
          0.04757944494485855,
          0.06897785514593124,
          0.10000000149011612
         ]
        }
       ],
       "layout": {
        "title": {
         "text": "batch/lr"
        },
        "yaxis": {
         "hoverformat": ".6f"
        }
       }
      },
      "text/html": [
       "<div id=\"0cb55059-5750-4cc6-ab3c-42bf86a74671\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"0cb55059-5750-4cc6-ab3c-42bf86a74671\")) {\n",
       "    Plotly.newPlot(\"0cb55059-5750-4cc6-ab3c-42bf86a74671\", [{\"name\": \"train/batch/lr\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], \"y\": [9.999999974752427e-07, 1.4497406937152846e-06, 2.1017481230956037e-06, 3.046989604627015e-06, 4.417344825924374e-06, 6.404004125215579e-06, 9.284145562560298e-06, 1.3459602996590547e-05, 1.951293415913824e-05, 2.8288694011280313e-05, 4.101126978639513e-05, 5.945570592302829e-05, 8.619535947218537e-05, 0.00012496091949287802, 0.0001811609254218638, 0.0002626363420858979, 0.0003807546163443476, 0.0005519954138435423, 0.0008002502145245671, 0.0011601552832871675, 0.00168192433193326, 0.0024383540730923414, 0.0035349810495972633, 0.005124805960804224, 0.007429639343172312, 0.010771050117909908, 0.015615230426192284, 0.02263803407549858, 0.03281927853822708, 0.04757944494485855, 0.06897785514593124, 0.10000000149011612], \"type\": \"scatter\", \"uid\": \"a42398fb-047c-41dd-821f-cf43a25d134e\"}], {\"title\": {\"text\": \"batch/lr\"}, \"yaxis\": {\"hoverformat\": \".6f\"}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"0cb55059-5750-4cc6-ab3c-42bf86a74671\")) {window._Plotly.Plots.resize(document.getElementById(\"0cb55059-5750-4cc6-ab3c-42bf86a74671\"));};})</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"0cb55059-5750-4cc6-ab3c-42bf86a74671\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"0cb55059-5750-4cc6-ab3c-42bf86a74671\")) {\n",
       "    Plotly.newPlot(\"0cb55059-5750-4cc6-ab3c-42bf86a74671\", [{\"name\": \"train/batch/lr\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], \"y\": [9.999999974752427e-07, 1.4497406937152846e-06, 2.1017481230956037e-06, 3.046989604627015e-06, 4.417344825924374e-06, 6.404004125215579e-06, 9.284145562560298e-06, 1.3459602996590547e-05, 1.951293415913824e-05, 2.8288694011280313e-05, 4.101126978639513e-05, 5.945570592302829e-05, 8.619535947218537e-05, 0.00012496091949287802, 0.0001811609254218638, 0.0002626363420858979, 0.0003807546163443476, 0.0005519954138435423, 0.0008002502145245671, 0.0011601552832871675, 0.00168192433193326, 0.0024383540730923414, 0.0035349810495972633, 0.005124805960804224, 0.007429639343172312, 0.010771050117909908, 0.015615230426192284, 0.02263803407549858, 0.03281927853822708, 0.04757944494485855, 0.06897785514593124, 0.10000000149011612], \"type\": \"scatter\", \"uid\": \"a42398fb-047c-41dd-821f-cf43a25d134e\"}], {\"title\": {\"text\": \"batch/lr\"}, \"yaxis\": {\"hoverformat\": \".6f\"}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"0cb55059-5750-4cc6-ab3c-42bf86a74671\")) {window._Plotly.Plots.resize(document.getElementById(\"0cb55059-5750-4cc6-ab3c-42bf86a74671\"));};})</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "keker.plot_kek_lr(logdir=\"logdir_lr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/384:  47% 15/32 [01:59<01:26,  5.08s/it, loss=2.8056]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roma/.virtualenvs/aseg_torch1/lib/python3.6/site-packages/ipykernel_launcher.py:113: UserWarning:\n",
      "\n",
      "Wrong example is found: all `labels_raw` < 0. Id=scene0509_00.merged\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/384: 100% 32/32 [03:33<00:00,  4.01s/it, loss=1.8679, train_iouf=0.0474, val_iouf=0.0666, val_loss=1.7088]\n",
      "Epoch 2/384: 100% 32/32 [03:30<00:00,  3.88s/it, loss=1.4250, train_iouf=0.0583, val_iouf=0.0684, val_loss=1.3071]\n",
      "Epoch 3/384: 100% 32/32 [03:32<00:00,  4.12s/it, loss=1.1929, train_iouf=0.0674, val_iouf=0.0749, val_loss=1.0398]\n",
      "Epoch 4/384: 100% 32/32 [03:31<00:00,  3.81s/it, loss=1.0792, train_iouf=0.0721, val_iouf=0.0784, val_loss=0.9314]\n",
      "Epoch 5/384: 100% 32/32 [03:31<00:00,  3.83s/it, loss=1.0113, train_iouf=0.0873, val_iouf=0.0944, val_loss=0.9001]\n",
      "Epoch 6/384: 100% 32/32 [03:33<00:00,  3.75s/it, loss=0.9490, train_iouf=0.0916, val_iouf=0.0960, val_loss=0.8626]\n",
      "Epoch 7/384: 100% 32/32 [03:35<00:00,  3.95s/it, loss=0.9411, train_iouf=0.0925, val_iouf=0.0967, val_loss=0.8761]\n",
      "Epoch 8/384: 100% 32/32 [03:37<00:00,  3.89s/it, loss=0.9300, train_iouf=0.1009, val_iouf=0.1057, val_loss=0.8356]\n",
      "Epoch 9/384: 100% 32/32 [03:35<00:00,  4.12s/it, loss=0.9368, train_iouf=0.1096, val_iouf=0.1128, val_loss=0.8406]\n",
      "Epoch 10/384: 100% 32/32 [03:35<00:00,  3.88s/it, loss=0.8744, train_iouf=0.1256, val_iouf=0.1351, val_loss=0.8086]\n",
      "Epoch 11/384: 100% 32/32 [03:35<00:00,  4.03s/it, loss=0.8643, train_iouf=0.1341, val_iouf=0.1339, val_loss=0.8276]\n",
      "Epoch 12/384: 100% 32/32 [03:35<00:00,  4.13s/it, loss=0.8449, train_iouf=0.1375, val_iouf=0.1481, val_loss=0.7726]\n",
      "Epoch 13/384: 100% 32/32 [03:34<00:00,  4.04s/it, loss=0.8558, train_iouf=0.1431, val_iouf=0.1408, val_loss=0.7902]\n",
      "Epoch 14/384: 100% 32/32 [03:35<00:00,  4.05s/it, loss=0.8425, train_iouf=0.1449, val_iouf=0.1572, val_loss=0.7930]\n",
      "Epoch 15/384: 100% 32/32 [03:34<00:00,  4.01s/it, loss=0.8093, train_iouf=0.1515, val_iouf=0.1623, val_loss=0.7579]\n",
      "Epoch 16/384: 100% 32/32 [03:33<00:00,  4.17s/it, loss=0.8155, train_iouf=0.1555, val_iouf=0.1604, val_loss=0.8643]\n",
      "Epoch 17/384: 100% 32/32 [03:36<00:00,  3.79s/it, loss=0.8097, train_iouf=0.1616, val_iouf=0.1715, val_loss=0.7469]\n",
      "Epoch 18/384: 100% 32/32 [03:36<00:00,  4.16s/it, loss=0.7986, train_iouf=0.1628, val_iouf=0.1665, val_loss=0.7016]\n",
      "Epoch 19/384: 100% 32/32 [03:37<00:00,  4.17s/it, loss=0.8027, train_iouf=0.1608, val_iouf=0.1633, val_loss=0.7495]\n",
      "Epoch 20/384: 100% 32/32 [03:42<00:00,  4.27s/it, loss=0.7599, train_iouf=0.1683, val_iouf=0.1711, val_loss=0.7376]\n",
      "Epoch 21/384: 100% 32/32 [03:36<00:00,  3.99s/it, loss=0.7729, train_iouf=0.1687, val_iouf=0.1535, val_loss=0.7917]\n",
      "Epoch 22/384: 100% 32/32 [03:32<00:00,  3.94s/it, loss=0.7855, train_iouf=0.1729, val_iouf=0.1736, val_loss=0.7368]\n",
      "Epoch 23/384: 100% 32/32 [03:30<00:00,  4.01s/it, loss=0.7705, train_iouf=0.1722, val_iouf=0.1756, val_loss=0.7346]\n",
      "Epoch 24/384: 100% 32/32 [03:33<00:00,  3.84s/it, loss=0.7749, train_iouf=0.1815, val_iouf=0.1912, val_loss=0.7030]\n",
      "Epoch 25/384: 100% 32/32 [03:32<00:00,  4.13s/it, loss=0.7916, train_iouf=0.1766, val_iouf=0.1754, val_loss=0.6919]\n",
      "Epoch 26/384: 100% 32/32 [03:36<00:00,  4.00s/it, loss=0.7784, train_iouf=0.1765, val_iouf=0.1708, val_loss=0.7883]\n",
      "Epoch 27/384: 100% 32/32 [03:33<00:00,  4.06s/it, loss=0.7085, train_iouf=0.1847, val_iouf=0.2136, val_loss=0.6603]\n",
      "Epoch 28/384: 100% 32/32 [03:37<00:00,  4.13s/it, loss=0.7297, train_iouf=0.1890, val_iouf=0.1731, val_loss=0.6890]\n",
      "Epoch 29/384: 100% 32/32 [03:35<00:00,  3.99s/it, loss=0.7668, train_iouf=0.1884, val_iouf=0.1853, val_loss=0.7909]\n",
      "Epoch 30/384: 100% 32/32 [03:33<00:00,  3.91s/it, loss=0.7419, train_iouf=0.1825, val_iouf=0.1969, val_loss=0.7075]\n",
      "Epoch 31/384: 100% 32/32 [03:32<00:00,  4.15s/it, loss=0.7492, train_iouf=0.1901, val_iouf=0.1932, val_loss=0.7131]\n",
      "Epoch 32/384: 100% 32/32 [03:31<00:00,  3.88s/it, loss=0.7261, train_iouf=0.1866, val_iouf=0.1753, val_loss=0.7165]\n",
      "Epoch 33/384: 100% 32/32 [03:31<00:00,  4.02s/it, loss=0.7360, train_iouf=0.1939, val_iouf=0.2089, val_loss=0.6791]\n",
      "Epoch 34/384: 100% 32/32 [03:34<00:00,  4.10s/it, loss=0.7198, train_iouf=0.1981, val_iouf=0.2011, val_loss=0.6253]\n",
      "Epoch 35/384: 100% 32/32 [03:33<00:00,  3.85s/it, loss=0.7407, train_iouf=0.1956, val_iouf=0.2193, val_loss=0.6324]\n",
      "Epoch 36/384: 100% 32/32 [03:34<00:00,  4.24s/it, loss=0.7420, train_iouf=0.1887, val_iouf=0.1679, val_loss=0.8200]\n",
      "Epoch 37/384: 100% 32/32 [03:36<00:00,  4.15s/it, loss=0.7176, train_iouf=0.1935, val_iouf=0.1878, val_loss=0.6968]\n",
      "Epoch 38/384: 100% 32/32 [03:32<00:00,  4.10s/it, loss=0.7275, train_iouf=0.1944, val_iouf=0.2041, val_loss=0.7588]\n",
      "Epoch 39/384: 100% 32/32 [03:33<00:00,  3.90s/it, loss=0.7426, train_iouf=0.1957, val_iouf=0.1830, val_loss=0.7064]\n",
      "Epoch 40/384: 100% 32/32 [03:36<00:00,  4.15s/it, loss=0.7480, train_iouf=0.1898, val_iouf=0.1705, val_loss=0.7729]\n",
      "Epoch 41/384: 100% 32/32 [03:44<00:00,  4.09s/it, loss=0.7002, train_iouf=0.2034, val_iouf=0.1811, val_loss=0.6847]\n",
      "Epoch 42/384: 100% 32/32 [03:34<00:00,  3.95s/it, loss=0.7158, train_iouf=0.2000, val_iouf=0.2114, val_loss=0.6549]\n",
      "Epoch 43/384: 100% 32/32 [03:33<00:00,  3.78s/it, loss=0.7447, train_iouf=0.1976, val_iouf=0.2142, val_loss=0.6207]\n",
      "Epoch 44/384: 100% 32/32 [03:31<00:00,  4.06s/it, loss=0.7035, train_iouf=0.1952, val_iouf=0.2285, val_loss=0.6361]\n",
      "Epoch 45/384: 100% 32/32 [03:32<00:00,  3.78s/it, loss=0.7019, train_iouf=0.2042, val_iouf=0.1947, val_loss=0.6552]\n",
      "Epoch 46/384: 100% 32/32 [03:33<00:00,  4.17s/it, loss=0.6901, train_iouf=0.2027, val_iouf=0.2163, val_loss=0.6183]\n",
      "Epoch 47/384: 100% 32/32 [03:32<00:00,  3.80s/it, loss=0.7061, train_iouf=0.2059, val_iouf=0.1965, val_loss=0.6842]\n",
      "Epoch 48/384: 100% 32/32 [03:32<00:00,  4.15s/it, loss=0.7173, train_iouf=0.1997, val_iouf=0.1782, val_loss=0.7461]\n",
      "Epoch 49/384: 100% 32/32 [03:29<00:00,  3.97s/it, loss=0.7124, train_iouf=0.2081, val_iouf=0.2221, val_loss=0.6203]\n",
      "Epoch 50/384: 100% 32/32 [03:32<00:00,  3.97s/it, loss=0.6945, train_iouf=0.2023, val_iouf=0.1938, val_loss=0.6870]\n",
      "Epoch 51/384: 100% 32/32 [03:35<00:00,  3.84s/it, loss=0.6880, train_iouf=0.2092, val_iouf=0.2074, val_loss=0.6646]\n",
      "Epoch 52/384: 100% 32/32 [03:31<00:00,  3.93s/it, loss=0.6675, train_iouf=0.2093, val_iouf=0.2161, val_loss=0.5935]\n",
      "Epoch 53/384: 100% 32/32 [03:34<00:00,  4.21s/it, loss=0.7122, train_iouf=0.2089, val_iouf=0.1759, val_loss=0.8080]\n",
      "Epoch 54/384: 100% 32/32 [03:30<00:00,  3.91s/it, loss=0.6841, train_iouf=0.2100, val_iouf=0.2057, val_loss=0.7306]\n",
      "Epoch 55/384: 100% 32/32 [03:34<00:00,  3.75s/it, loss=0.6759, train_iouf=0.2051, val_iouf=0.2265, val_loss=0.6236]\n",
      "Epoch 56/384: 100% 32/32 [03:32<00:00,  4.03s/it, loss=0.6890, train_iouf=0.2050, val_iouf=0.2034, val_loss=0.6379]\n",
      "Epoch 57/384: 100% 32/32 [03:32<00:00,  4.17s/it, loss=0.6820, train_iouf=0.2121, val_iouf=0.1997, val_loss=0.6490]\n",
      "Epoch 58/384: 100% 32/32 [03:34<00:00,  3.86s/it, loss=0.6744, train_iouf=0.2162, val_iouf=0.2288, val_loss=0.6092]\n",
      "Epoch 59/384: 100% 32/32 [03:32<00:00,  3.97s/it, loss=0.6686, train_iouf=0.2122, val_iouf=0.2427, val_loss=0.6379]\n",
      "Epoch 60/384: 100% 32/32 [03:34<00:00,  3.78s/it, loss=0.6876, train_iouf=0.2072, val_iouf=0.2301, val_loss=0.6837]\n",
      "Epoch 61/384: 100% 32/32 [03:31<00:00,  3.92s/it, loss=0.6944, train_iouf=0.2183, val_iouf=0.2279, val_loss=0.6411]\n",
      "Epoch 62/384: 100% 32/32 [03:35<00:00,  4.14s/it, loss=0.6421, train_iouf=0.2228, val_iouf=0.2163, val_loss=0.6179]\n",
      "Epoch 63/384: 100% 32/32 [03:34<00:00,  4.14s/it, loss=0.6580, train_iouf=0.2253, val_iouf=0.2338, val_loss=0.6134]\n",
      "Epoch 64/384: 100% 32/32 [03:33<00:00,  3.72s/it, loss=0.6854, train_iouf=0.2153, val_iouf=0.1824, val_loss=0.7437]\n",
      "Epoch 65/384: 100% 32/32 [03:31<00:00,  4.12s/it, loss=0.6788, train_iouf=0.2115, val_iouf=0.2287, val_loss=0.7240]\n",
      "Epoch 66/384: 100% 32/32 [03:34<00:00,  4.24s/it, loss=0.6853, train_iouf=0.2129, val_iouf=0.2371, val_loss=0.6535]\n",
      "Epoch 67/384: 100% 32/32 [03:31<00:00,  3.87s/it, loss=0.6780, train_iouf=0.2165, val_iouf=0.2348, val_loss=0.5962]\n",
      "Epoch 68/384: 100% 32/32 [03:32<00:00,  3.63s/it, loss=0.6772, train_iouf=0.2198, val_iouf=0.1584, val_loss=0.9157]\n",
      "Epoch 69/384: 100% 32/32 [03:30<00:00,  3.84s/it, loss=0.6509, train_iouf=0.2204, val_iouf=0.2434, val_loss=0.6073]\n",
      "Epoch 70/384: 100% 32/32 [03:32<00:00,  3.82s/it, loss=0.6666, train_iouf=0.2179, val_iouf=0.1826, val_loss=0.8197]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/384: 100% 32/32 [03:31<00:00,  3.81s/it, loss=0.6883, train_iouf=0.2166, val_iouf=0.2079, val_loss=0.6918]\n",
      "Epoch 72/384: 100% 32/32 [03:31<00:00,  3.94s/it, loss=0.6349, train_iouf=0.2298, val_iouf=0.2119, val_loss=0.7668]\n",
      "Epoch 73/384: 100% 32/32 [03:32<00:00,  3.99s/it, loss=0.6665, train_iouf=0.2323, val_iouf=0.2244, val_loss=0.5945]\n",
      "Epoch 74/384: 100% 32/32 [03:34<00:00,  3.84s/it, loss=0.6592, train_iouf=0.2359, val_iouf=0.2453, val_loss=0.5759]\n",
      "Epoch 75/384: 100% 32/32 [03:32<00:00,  3.72s/it, loss=0.6365, train_iouf=0.2322, val_iouf=0.2299, val_loss=0.5873]\n",
      "Epoch 76/384: 100% 32/32 [03:34<00:00,  4.04s/it, loss=0.6734, train_iouf=0.2204, val_iouf=0.2407, val_loss=0.6186]\n",
      "Epoch 77/384: 100% 32/32 [03:32<00:00,  3.93s/it, loss=0.6583, train_iouf=0.2254, val_iouf=0.2314, val_loss=0.6384]\n",
      "Epoch 78/384: 100% 32/32 [03:37<00:00,  4.15s/it, loss=0.6466, train_iouf=0.2327, val_iouf=0.2415, val_loss=0.6240]\n",
      "Epoch 79/384: 100% 32/32 [03:32<00:00,  3.87s/it, loss=0.6588, train_iouf=0.2263, val_iouf=0.2416, val_loss=0.6828]\n",
      "Epoch 80/384: 100% 32/32 [03:33<00:00,  4.01s/it, loss=0.6291, train_iouf=0.2478, val_iouf=0.2439, val_loss=0.5793]\n",
      "Epoch 81/384: 100% 32/32 [03:32<00:00,  3.96s/it, loss=0.6213, train_iouf=0.2396, val_iouf=0.2606, val_loss=0.5619]\n",
      "Epoch 82/384: 100% 32/32 [03:32<00:00,  4.14s/it, loss=0.6353, train_iouf=0.2396, val_iouf=0.2183, val_loss=0.6943]\n",
      "Epoch 83/384: 100% 32/32 [03:31<00:00,  3.95s/it, loss=0.6445, train_iouf=0.2385, val_iouf=0.2302, val_loss=0.6649]\n",
      "Epoch 84/384: 100% 32/32 [03:31<00:00,  3.75s/it, loss=0.6324, train_iouf=0.2373, val_iouf=0.2343, val_loss=0.6777]\n",
      "Epoch 85/384: 100% 32/32 [03:32<00:00,  4.26s/it, loss=0.6492, train_iouf=0.2317, val_iouf=0.2110, val_loss=0.6650]\n",
      "Epoch 86/384: 100% 32/32 [03:33<00:00,  4.11s/it, loss=0.6408, train_iouf=0.2426, val_iouf=0.2152, val_loss=0.6474]\n",
      "Epoch 87/384: 100% 32/32 [03:32<00:00,  3.93s/it, loss=0.6825, train_iouf=0.2326, val_iouf=0.2553, val_loss=0.6196]\n",
      "Epoch 88/384: 100% 32/32 [03:30<00:00,  3.84s/it, loss=0.6460, train_iouf=0.2407, val_iouf=0.2558, val_loss=0.6487]\n",
      "Epoch 89/384: 100% 32/32 [03:32<00:00,  3.68s/it, loss=0.6457, train_iouf=0.2403, val_iouf=0.2331, val_loss=0.6536]\n",
      "Epoch 90/384: 100% 32/32 [03:34<00:00,  3.76s/it, loss=0.6265, train_iouf=0.2525, val_iouf=0.2789, val_loss=0.5639]\n",
      "Epoch 91/384: 100% 32/32 [03:33<00:00,  3.92s/it, loss=0.6529, train_iouf=0.2458, val_iouf=0.2591, val_loss=0.5933]\n",
      "Epoch 92/384: 100% 32/32 [03:31<00:00,  3.82s/it, loss=0.6534, train_iouf=0.2390, val_iouf=0.2352, val_loss=0.5995]\n",
      "Epoch 93/384: 100% 32/32 [03:32<00:00,  3.81s/it, loss=0.6463, train_iouf=0.2445, val_iouf=0.2687, val_loss=0.6178]\n",
      "Epoch 94/384: 100% 32/32 [03:34<00:00,  3.93s/it, loss=0.6735, train_iouf=0.2372, val_iouf=0.2859, val_loss=0.5769]\n",
      "Epoch 95/384: 100% 32/32 [03:29<00:00,  3.86s/it, loss=0.6426, train_iouf=0.2479, val_iouf=0.2457, val_loss=0.6341]\n",
      "Epoch 96/384: 100% 32/32 [03:31<00:00,  3.92s/it, loss=0.6475, train_iouf=0.2439, val_iouf=0.2443, val_loss=0.6203]\n",
      "Epoch 97/384: 100% 32/32 [03:31<00:00,  4.08s/it, loss=0.6530, train_iouf=0.2380, val_iouf=0.2602, val_loss=0.5793]\n",
      "Epoch 98/384: 100% 32/32 [03:30<00:00,  4.15s/it, loss=0.6386, train_iouf=0.2424, val_iouf=0.2887, val_loss=0.5918]\n",
      "Epoch 99/384: 100% 32/32 [03:33<00:00,  4.04s/it, loss=0.6708, train_iouf=0.2466, val_iouf=0.1865, val_loss=0.8431]\n",
      "Epoch 100/384: 100% 32/32 [03:33<00:00,  3.85s/it, loss=0.6372, train_iouf=0.2355, val_iouf=0.2542, val_loss=0.6295]\n",
      "Epoch 101/384: 100% 32/32 [03:32<00:00,  4.34s/it, loss=0.6376, train_iouf=0.2450, val_iouf=0.2231, val_loss=0.6368]\n",
      "Epoch 102/384: 100% 32/32 [03:34<00:00,  3.84s/it, loss=0.6554, train_iouf=0.2475, val_iouf=0.2426, val_loss=0.7021]\n",
      "Epoch 103/384: 100% 32/32 [03:31<00:00,  3.72s/it, loss=0.6039, train_iouf=0.2463, val_iouf=0.2093, val_loss=0.7395]\n",
      "Epoch 104/384: 100% 32/32 [03:33<00:00,  3.87s/it, loss=0.6548, train_iouf=0.2514, val_iouf=0.2743, val_loss=0.5872]\n",
      "Epoch 105/384: 100% 32/32 [03:31<00:00,  3.88s/it, loss=0.6526, train_iouf=0.2359, val_iouf=0.2581, val_loss=0.6034]\n",
      "Epoch 106/384: 100% 32/32 [03:34<00:00,  3.86s/it, loss=0.6344, train_iouf=0.2502, val_iouf=0.1729, val_loss=0.9638]\n",
      "Epoch 107/384: 100% 32/32 [03:32<00:00,  3.95s/it, loss=0.5964, train_iouf=0.2578, val_iouf=0.2229, val_loss=0.6263]\n",
      "Epoch 108/384: 100% 32/32 [03:32<00:00,  4.06s/it, loss=0.6187, train_iouf=0.2586, val_iouf=0.2765, val_loss=0.5480]\n",
      "Epoch 109/384: 100% 32/32 [03:33<00:00,  3.94s/it, loss=0.6455, train_iouf=0.2619, val_iouf=0.2727, val_loss=0.5536]\n",
      "Epoch 110/384: 100% 32/32 [03:31<00:00,  3.87s/it, loss=0.6249, train_iouf=0.2529, val_iouf=0.2341, val_loss=0.6241]\n",
      "Epoch 111/384: 100% 32/32 [03:30<00:00,  3.92s/it, loss=0.6245, train_iouf=0.2568, val_iouf=0.2172, val_loss=0.7248]\n",
      "Epoch 112/384: 100% 32/32 [03:34<00:00,  3.85s/it, loss=0.6115, train_iouf=0.2583, val_iouf=0.2865, val_loss=0.5458]\n",
      "Epoch 113/384: 100% 32/32 [03:31<00:00,  4.06s/it, loss=0.6241, train_iouf=0.2595, val_iouf=0.2547, val_loss=0.6533]\n",
      "Epoch 114/384: 100% 32/32 [03:33<00:00,  4.05s/it, loss=0.6067, train_iouf=0.2590, val_iouf=0.2793, val_loss=0.5372]\n",
      "Epoch 115/384: 100% 32/32 [03:36<00:00,  4.01s/it, loss=0.6101, train_iouf=0.2673, val_iouf=0.2164, val_loss=0.6936]\n",
      "Epoch 116/384: 100% 32/32 [03:31<00:00,  3.87s/it, loss=0.6114, train_iouf=0.2594, val_iouf=0.2460, val_loss=0.5986]\n",
      "Epoch 117/384: 100% 32/32 [03:31<00:00,  3.92s/it, loss=0.6466, train_iouf=0.2509, val_iouf=0.2500, val_loss=0.7277]\n",
      "Epoch 118/384: 100% 32/32 [03:33<00:00,  3.83s/it, loss=0.6194, train_iouf=0.2528, val_iouf=0.2740, val_loss=0.6333]\n",
      "Epoch 119/384: 100% 32/32 [03:31<00:00,  3.91s/it, loss=0.6191, train_iouf=0.2652, val_iouf=0.2857, val_loss=0.5727]\n",
      "Epoch 120/384: 100% 32/32 [03:34<00:00,  4.10s/it, loss=0.6118, train_iouf=0.2665, val_iouf=0.2804, val_loss=0.5389]\n",
      "Epoch 121/384: 100% 32/32 [03:35<00:00,  3.69s/it, loss=0.6058, train_iouf=0.2623, val_iouf=0.2412, val_loss=0.6303]\n",
      "Epoch 122/384: 100% 32/32 [03:32<00:00,  3.95s/it, loss=0.5897, train_iouf=0.2671, val_iouf=0.2714, val_loss=0.5803]\n",
      "Epoch 123/384: 100% 32/32 [03:33<00:00,  4.27s/it, loss=0.6040, train_iouf=0.2651, val_iouf=0.2293, val_loss=0.7013]\n",
      "Epoch 124/384: 100% 32/32 [03:33<00:00,  3.73s/it, loss=0.5987, train_iouf=0.2711, val_iouf=0.2816, val_loss=0.5471]\n",
      "Epoch 125/384: 100% 32/32 [03:30<00:00,  3.67s/it, loss=0.6156, train_iouf=0.2685, val_iouf=0.2504, val_loss=0.7187]\n",
      "Epoch 126/384: 100% 32/32 [03:34<00:00,  3.62s/it, loss=0.6156, train_iouf=0.2643, val_iouf=0.2966, val_loss=0.5810]\n",
      "Epoch 127/384: 100% 32/32 [03:32<00:00,  3.91s/it, loss=0.6090, train_iouf=0.2632, val_iouf=0.2685, val_loss=0.6422]\n",
      "Epoch 128/384: 100% 32/32 [03:32<00:00,  4.00s/it, loss=0.6100, train_iouf=0.2703, val_iouf=0.2764, val_loss=0.5405]\n",
      "Epoch 129/384: 100% 32/32 [03:32<00:00,  4.28s/it, loss=0.6069, train_iouf=0.2677, val_iouf=0.2064, val_loss=0.6537]\n",
      "Epoch 130/384: 100% 32/32 [03:30<00:00,  3.81s/it, loss=0.6255, train_iouf=0.2644, val_iouf=0.2832, val_loss=0.5958]\n",
      "Epoch 131/384: 100% 32/32 [03:32<00:00,  3.91s/it, loss=0.6297, train_iouf=0.2627, val_iouf=0.2675, val_loss=0.5965]\n",
      "Epoch 132/384: 100% 32/32 [03:31<00:00,  3.97s/it, loss=0.6035, train_iouf=0.2689, val_iouf=0.2105, val_loss=0.8266]\n",
      "Epoch 133/384: 100% 32/32 [03:32<00:00,  4.05s/it, loss=0.6120, train_iouf=0.2658, val_iouf=0.2505, val_loss=0.5810]\n",
      "Epoch 134/384: 100% 32/32 [03:32<00:00,  4.22s/it, loss=0.6174, train_iouf=0.2697, val_iouf=0.2371, val_loss=0.6655]\n",
      "Epoch 135/384: 100% 32/32 [03:31<00:00,  3.68s/it, loss=0.6207, train_iouf=0.2657, val_iouf=0.2500, val_loss=0.7059]\n",
      "Epoch 136/384: 100% 32/32 [03:32<00:00,  4.00s/it, loss=0.5983, train_iouf=0.2709, val_iouf=0.2928, val_loss=0.5374]\n",
      "Epoch 137/384: 100% 32/32 [03:33<00:00,  3.68s/it, loss=0.6054, train_iouf=0.2742, val_iouf=0.2893, val_loss=0.5425]\n",
      "Epoch 138/384: 100% 32/32 [03:32<00:00,  3.86s/it, loss=0.5760, train_iouf=0.2844, val_iouf=0.2535, val_loss=0.6186]\n",
      "Epoch 139/384: 100% 32/32 [03:31<00:00,  3.84s/it, loss=0.6023, train_iouf=0.2763, val_iouf=0.2544, val_loss=0.6250]\n",
      "Epoch 140/384: 100% 32/32 [03:34<00:00,  3.81s/it, loss=0.6095, train_iouf=0.2777, val_iouf=0.2776, val_loss=0.6216]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141/384: 100% 32/32 [03:29<00:00,  3.80s/it, loss=0.6184, train_iouf=0.2678, val_iouf=0.2866, val_loss=0.6041]\n",
      "Epoch 142/384: 100% 32/32 [03:32<00:00,  3.87s/it, loss=0.6036, train_iouf=0.2737, val_iouf=0.2644, val_loss=0.5956]\n",
      "Epoch 143/384: 100% 32/32 [03:33<00:00,  3.88s/it, loss=0.6276, train_iouf=0.2588, val_iouf=0.2584, val_loss=0.5971]\n",
      "Epoch 144/384: 100% 32/32 [03:33<00:00,  4.06s/it, loss=0.6207, train_iouf=0.2648, val_iouf=0.2746, val_loss=0.6577]\n",
      "Epoch 145/384: 100% 32/32 [03:32<00:00,  4.02s/it, loss=0.5909, train_iouf=0.2801, val_iouf=0.2929, val_loss=0.6417]\n",
      "Epoch 146/384: 100% 32/32 [03:32<00:00,  3.81s/it, loss=0.5967, train_iouf=0.2833, val_iouf=0.2856, val_loss=0.6001]\n",
      "Epoch 147/384: 100% 32/32 [03:33<00:00,  3.98s/it, loss=0.6317, train_iouf=0.2687, val_iouf=0.2584, val_loss=0.5624]\n",
      "Epoch 148/384: 100% 32/32 [03:33<00:00,  3.97s/it, loss=0.5990, train_iouf=0.2756, val_iouf=0.2629, val_loss=0.5772]\n",
      "Epoch 149/384: 100% 32/32 [03:32<00:00,  3.81s/it, loss=0.5969, train_iouf=0.2765, val_iouf=0.2855, val_loss=0.5581]\n",
      "Epoch 150/384: 100% 32/32 [03:33<00:00,  4.37s/it, loss=0.5976, train_iouf=0.2750, val_iouf=0.2482, val_loss=0.7656]\n",
      "Epoch 151/384: 100% 32/32 [03:31<00:00,  3.92s/it, loss=0.6165, train_iouf=0.2663, val_iouf=0.3015, val_loss=0.5518]\n",
      "Epoch 152/384: 100% 32/32 [03:33<00:00,  3.81s/it, loss=0.5964, train_iouf=0.2803, val_iouf=0.3141, val_loss=0.5666]\n",
      "Epoch 153/384: 100% 32/32 [03:32<00:00,  3.93s/it, loss=0.5873, train_iouf=0.2835, val_iouf=0.2727, val_loss=0.5657]\n",
      "Epoch 154/384: 100% 32/32 [03:36<00:00,  4.16s/it, loss=0.6178, train_iouf=0.2696, val_iouf=0.2163, val_loss=0.6576]\n",
      "Epoch 155/384: 100% 32/32 [03:30<00:00,  3.97s/it, loss=0.6166, train_iouf=0.2715, val_iouf=0.2543, val_loss=0.6430]\n",
      "Epoch 156/384: 100% 32/32 [03:31<00:00,  3.99s/it, loss=0.6023, train_iouf=0.2766, val_iouf=0.2739, val_loss=0.6830]\n",
      "Epoch 157/384: 100% 32/32 [03:33<00:00,  4.12s/it, loss=0.6431, train_iouf=0.2732, val_iouf=0.2636, val_loss=0.5889]\n",
      "Epoch 158/384: 100% 32/32 [03:31<00:00,  3.85s/it, loss=0.6116, train_iouf=0.2761, val_iouf=0.2683, val_loss=0.7107]\n",
      "Epoch 159/384: 100% 32/32 [03:31<00:00,  3.93s/it, loss=0.6255, train_iouf=0.2642, val_iouf=0.2268, val_loss=0.6109]\n",
      "Epoch 160/384: 100% 32/32 [03:33<00:00,  3.85s/it, loss=0.6029, train_iouf=0.2742, val_iouf=0.2905, val_loss=0.6145]\n",
      "Epoch 161/384: 100% 32/32 [03:33<00:00,  3.85s/it, loss=0.6103, train_iouf=0.2817, val_iouf=0.2772, val_loss=0.5933]\n",
      "Epoch 162/384: 100% 32/32 [03:33<00:00,  3.96s/it, loss=0.5806, train_iouf=0.2788, val_iouf=0.2287, val_loss=0.6660]\n",
      "Epoch 163/384: 100% 32/32 [03:30<00:00,  3.87s/it, loss=0.5957, train_iouf=0.2868, val_iouf=0.3099, val_loss=0.5673]\n",
      "Epoch 164/384: 100% 32/32 [03:31<00:00,  4.02s/it, loss=0.6005, train_iouf=0.2834, val_iouf=0.2921, val_loss=0.6151]\n",
      "Epoch 165/384: 100% 32/32 [03:33<00:00,  3.85s/it, loss=0.5929, train_iouf=0.2871, val_iouf=0.2518, val_loss=0.6307]\n",
      "Epoch 166/384: 100% 32/32 [03:35<00:00,  3.76s/it, loss=0.5786, train_iouf=0.2828, val_iouf=0.2760, val_loss=0.5615]\n",
      "Epoch 167/384: 100% 32/32 [03:33<00:00,  4.06s/it, loss=0.5910, train_iouf=0.2772, val_iouf=0.2859, val_loss=0.6426]\n",
      "Epoch 168/384: 100% 32/32 [03:33<00:00,  3.94s/it, loss=0.5841, train_iouf=0.2852, val_iouf=0.2719, val_loss=0.5259]\n",
      "Epoch 169/384: 100% 32/32 [03:32<00:00,  3.91s/it, loss=0.5992, train_iouf=0.2778, val_iouf=0.2969, val_loss=0.5937]\n",
      "Epoch 170/384: 100% 32/32 [03:33<00:00,  3.87s/it, loss=0.5869, train_iouf=0.2766, val_iouf=0.2864, val_loss=0.5359]\n",
      "Epoch 171/384: 100% 32/32 [03:32<00:00,  3.93s/it, loss=0.5786, train_iouf=0.2791, val_iouf=0.2844, val_loss=0.6396]\n",
      "Epoch 172/384: 100% 32/32 [03:32<00:00,  3.84s/it, loss=0.5981, train_iouf=0.2685, val_iouf=0.2860, val_loss=0.5804]\n",
      "Epoch 173/384: 100% 32/32 [03:34<00:00,  4.05s/it, loss=0.6110, train_iouf=0.2742, val_iouf=0.2986, val_loss=0.6201]\n",
      "Epoch 174/384: 100% 32/32 [03:35<00:00,  3.87s/it, loss=0.5972, train_iouf=0.2838, val_iouf=0.3186, val_loss=0.5516]\n",
      "Epoch 175/384: 100% 32/32 [03:35<00:00,  3.93s/it, loss=0.5939, train_iouf=0.2827, val_iouf=0.2327, val_loss=0.6290]\n",
      "Epoch 176/384: 100% 32/32 [03:34<00:00,  4.54s/it, loss=0.5831, train_iouf=0.2866, val_iouf=0.2759, val_loss=0.5977]\n",
      "Epoch 177/384: 100% 32/32 [03:35<00:00,  4.06s/it, loss=0.5881, train_iouf=0.2928, val_iouf=0.2772, val_loss=0.5896]\n",
      "Epoch 178/384: 100% 32/32 [03:31<00:00,  3.96s/it, loss=0.5635, train_iouf=0.2910, val_iouf=0.3213, val_loss=0.5227]\n",
      "Epoch 179/384: 100% 32/32 [03:32<00:00,  3.67s/it, loss=0.5903, train_iouf=0.2872, val_iouf=0.2841, val_loss=0.5895]\n",
      "Epoch 180/384: 100% 32/32 [03:31<00:00,  3.80s/it, loss=0.6078, train_iouf=0.2889, val_iouf=0.2361, val_loss=0.6559]\n",
      "Epoch 181/384: 100% 32/32 [03:34<00:00,  4.04s/it, loss=0.6062, train_iouf=0.2849, val_iouf=0.2732, val_loss=0.5924]\n",
      "Epoch 182/384: 100% 32/32 [03:33<00:00,  3.96s/it, loss=0.5920, train_iouf=0.2773, val_iouf=0.2913, val_loss=0.5477]\n",
      "Epoch 183/384: 100% 32/32 [03:32<00:00,  4.42s/it, loss=0.5726, train_iouf=0.2910, val_iouf=0.2677, val_loss=0.5806]\n",
      "Epoch 184/384: 100% 32/32 [03:31<00:00,  4.02s/it, loss=0.6212, train_iouf=0.2712, val_iouf=0.2828, val_loss=0.5740]\n",
      "Epoch 185/384: 100% 32/32 [03:32<00:00,  3.72s/it, loss=0.5849, train_iouf=0.2761, val_iouf=0.2549, val_loss=0.5925]\n",
      "Epoch 186/384: 100% 32/32 [03:34<00:00,  3.92s/it, loss=0.5819, train_iouf=0.2912, val_iouf=0.2989, val_loss=0.5762]\n",
      "Epoch 187/384: 100% 32/32 [03:32<00:00,  4.24s/it, loss=0.5730, train_iouf=0.2912, val_iouf=0.3099, val_loss=0.5294]\n",
      "Epoch 188/384:   0% 0/32 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# Ok, now let's start training!\n",
    "# It's as simple as:\n",
    "keker.kek_one_cycle(cycle_len=params['n_epoch'], \n",
    "                    max_lr=params['max_lr'],  \n",
    "                    div_factor=1000, increase_fraction=0.1, \n",
    "                    logdir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keker.plot_kek(logdir=logdir, metrics=[\"val_iouf\", \"train_iouf\"], step=\"epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "469.333px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
