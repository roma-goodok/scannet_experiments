{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roma/.virtualenvs/aseg_torch1/lib/python3.6/site-packages/kekas/keker.py:9: UserWarning: Error 'No module named 'apex''' during importing apex library. To use mixed precison you should install it from https://github.com/NVIDIA/apex\n",
      "  warnings.warn(f\"Error '{e}'' during importing apex library. To use mixed precison\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "#import cv2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from pdb import set_trace as st\n",
    "\n",
    "#import pretrainedmodels as pm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "#from albumentations import Compose, JpegCompression, CLAHE, RandomRotate90, Transpose, ShiftScaleRotate, \\\n",
    "#        Blur, OpticalDistortion, GridDistortion, HueSaturationValue, Flip, VerticalFlip\n",
    "\n",
    "from kekas import Keker, DataOwner, DataKek\n",
    "from kekas.transformations import Transformer, to_torch, normalize\n",
    "from kekas.metrics import accuracy\n",
    "from kekas.modules import Flatten, AdaptiveConcatPool2d\n",
    "from kekas.callbacks import Callback, Callbacks, DebuggerCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai_sparse # 3D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparseconvnet as scn\n",
    "\n",
    "from fastai_sparse import utils, visualize\n",
    "from fastai_sparse.utils import log\n",
    "#from fastai_sparse.data import DataSourceConfig, MeshesDataset, SparseDataBunch\n",
    "#from fastai_sparse.learner import SparseModelConfig, Learner\n",
    "#from fastai_sparse.callbacks import TimeLogger, SaveModelCallback, CSVLogger\n",
    "from fastai_sparse.transforms import Transform, Compose\n",
    "\n",
    "from data import merge_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment environment and system metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import neptune\n",
    "#from neptune_callbacks import NeptuneMonitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_epoch': 384, 'max_lr': 2.0, 'wd': 0.0001}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params={'n_epoch': 384,\n",
    "        'max_lr': 2.0,\n",
    "        'wd':0.0001\n",
    "        }\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('NEPTUNE_API_TOKEN.txt','r') as f:\n",
    "#    NEPTUNE_API_TOKEN = f.readline().splitlines()[0]\n",
    "#    \n",
    "#neptune.init(api_token=NEPTUNE_API_TOKEN,\n",
    "#             project_qualified_name='roma-goodok/fastai-sparse-scannet')\n",
    "#\n",
    "## create experiment in the project defined above\n",
    "#exp = neptune.create_experiment(params=params)\n",
    "#print(exp.id)\n",
    "#exp.append_tag('study')\n",
    "#exp.append_tag('kekas')\n",
    "#exp.append_tag('unet24')\n",
    "#exp.append_tag('1cycle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: kekas_03\n",
      "Logdir: logdir/kekas_03\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    experiment_name = exp.id\n",
    "except Exception as e:\n",
    "    experiment_name = \"kekas_03\"\n",
    "\n",
    "print(\"Experiment:\", experiment_name)\n",
    "logdir = os.path.join('logdir', experiment_name)\n",
    "Path(logdir).mkdir(parents=True, exist_ok=True)\n",
    "print(\"Logdir:\", logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "virtualenv:     (aseg_torch1) \n",
      "python:         3.6.8\n",
      "nvidia driver:  b'384.130'\n",
      "nvidia cuda:    9.0, V9.0.176\n",
      "cudnn:          7.1.4\n",
      "torch:          1.0.0\n",
      "pandas:         0.24.2\n",
      "kekas:          0.1.17\n",
      "fastai:         1.0.48\n",
      "fastai_sparse:  0.0.4.dev0\n"
     ]
    }
   ],
   "source": [
    "utils.watermark(pandas=True, kekas=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33md5c7ab0\u001b[m kekas: train to reproduce FASSCN-23 :completed\r\n",
      "\u001b[33ma96a67d\u001b[m kekas: train to reproduce FASSCN-23 : in progress\r\n",
      "\u001b[33meb7c0b3\u001b[m kekas: train to reproduce FASSCN-23 experiment started...\r\n"
     ]
    }
   ],
   "source": [
    "!git log1 -n3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Apr 21 23:50:37 2019       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 384.130                Driver Version: 384.130                   |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:28:00.0  On |                  N/A |\r\n",
      "| 31%   62C    P2    69W / 250W |   7029MiB / 11163MiB |      4%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:29:00.0 Off |                  N/A |\r\n",
      "| 29%   55C    P0    69W / 250W |     11MiB / 11172MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0      1428      G   /usr/lib/xorg/Xorg                           563MiB |\r\n",
      "|    0      2803      G   compiz                                       287MiB |\r\n",
      "|    0      3159      G   /usr/lib/firefox/firefox                     613MiB |\r\n",
      "|    0      4548      G   ...-token=984E0E17258E906521CB9B221D39B059   105MiB |\r\n",
      "|    0     11199      C   ...oma/.virtualenvs/aseg_torch1/bin/python  5455MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name:            AMD Ryzen 7 1700 Eight-Core Processor\r\n"
     ]
    }
   ],
   "source": [
    "!lscpu | grep \"Model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter notebook display options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:70% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "utils.wide_notebook()\n",
    "# uncomment this lines if you want switch off interactive and save visaulisation as screenshoots:\n",
    "# For rendering run command in terminal:    `chromium-browser --remote-debugging-port=9222`\n",
    "if False:\n",
    "    visualize.options.interactive = False\n",
    "    visualize.options.save_images = True\n",
    "    visualize.options.verbose = True\n",
    "    visualize.options.filename_pattern_image = Path('images', experiment_name, 'fig_{fig_number}')\n",
    "else:\n",
    "    for key, o in visualize.options.__dataclass_fields__.items():\n",
    "        setattr(visualize.options, key, o.default)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see how download and preprocess data by the following link from fastai_sparse library: https://github.com/goodok/fastai_sparse/tree/master/examples/scannet/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scene0000_01.merged.ply']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SOURCE_DIR = Path('data', 'scannet_merged_ply')\n",
    "assert SOURCE_DIR.exists(), \"Run prepare_data.ipynb\"\n",
    "\n",
    "definition_of_spliting_dir = Path('data', 'ScanNet_Tasks_Benchmark')\n",
    "assert definition_of_spliting_dir.exists()\n",
    "\n",
    "\n",
    "os.listdir(SOURCE_DIR / 'scene0000_01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_files(path, ext='merged.ply'):\n",
    "    pattern = str(path / '*' / ('*' + ext))\n",
    "    fnames = glob.glob(pattern)\n",
    "    return fnames\n",
    "\n",
    "def get_df_list(verbose=0):\n",
    "    # train /valid / test splits\n",
    "    fn_lists = {}\n",
    "\n",
    "    fn_lists['train'] = definition_of_spliting_dir / 'scannetv1_train.txt'\n",
    "    fn_lists['valid'] = definition_of_spliting_dir / 'scannetv1_val.txt'\n",
    "    fn_lists['test'] = definition_of_spliting_dir / 'scannetv1_test.txt'\n",
    "\n",
    "    for datatype in ['train', 'valid', 'test']:\n",
    "        assert fn_lists[datatype].exists(), datatype\n",
    "\n",
    "    dfs = {}\n",
    "    total = 0\n",
    "    for datatype in ['train', 'valid', 'test']:\n",
    "        df = pd.read_csv(fn_lists[datatype], header=None, names=['example_id'])\n",
    "        df = df.assign(datatype=datatype)\n",
    "        df = df.assign(subdir=df.example_id)\n",
    "        df = df.sort_values('example_id')\n",
    "        dfs[datatype] = df\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"{datatype:5} counts: {len(df):>4}\")\n",
    "        \n",
    "        total += len(df)\n",
    "    if verbose:\n",
    "        print(f\"total:     {total}\")\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train counts: 1045\n",
      "valid counts:  156\n",
      "test  counts:  312\n",
      "total:     1513\n"
     ]
    }
   ],
   "source": [
    "df_list = get_df_list(verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>datatype</th>\n",
       "      <th>subdir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>scene0000_00</td>\n",
       "      <td>train</td>\n",
       "      <td>scene0000_00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>scene0000_01</td>\n",
       "      <td>train</td>\n",
       "      <td>scene0000_01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>scene0000_02</td>\n",
       "      <td>train</td>\n",
       "      <td>scene0000_02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>scene0001_00</td>\n",
       "      <td>train</td>\n",
       "      <td>scene0001_00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>scene0001_01</td>\n",
       "      <td>train</td>\n",
       "      <td>scene0001_01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       example_id datatype        subdir\n",
       "827  scene0000_00    train  scene0000_00\n",
       "828  scene0000_01    train  scene0000_01\n",
       "829  scene0000_02    train  scene0000_02\n",
       "496  scene0001_00    train  scene0001_00\n",
       "497  scene0001_01    train  scene0001_01"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list['train'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scene0000_00.merged.ply']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(os.path.join(SOURCE_DIR, 'scene0000_00'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai_sparse.data_items  import MeshItem, PointsItem\n",
    "from fastai_sparse.learner import SparseModelConfig\n",
    "import transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at first we need to create a reader function that will define how image will be opened\n",
    "def reader_fn(i, row):\n",
    "    fn = SOURCE_DIR / row['subdir'] / f'{row[\"example_id\"]}.merged.ply'\n",
    "    m = MeshItem.from_file(fn, label_field='label')\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MeshItem (scene0000_00.merged.ply)\n",
      "vertices:                shape: (81369, 3)            dtype: float64        min:   -0.01657,  max:    8.74040,  mean:    3.19051\n",
      "faces:                   shape: (153587, 3)           dtype: int64          min:          0,  max:      81368,  mean: 40549.68796\n",
      "colors:                  shape: (81369, 4)            dtype: uint8          min:    1.00000,  max:  255.00000,  mean:  145.80430\n",
      "labels:                  shape: (81369,)              dtype: uint16         min:    0.00000,  max:  230.00000,  mean:   12.97057\n",
      "Colors from vertices\n",
      "Labels from vertices\n"
     ]
    }
   ],
   "source": [
    "m = reader_fn(0, df_list['train'].iloc[0])\n",
    "m.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map relevant classes to {0,1,...,19}, and ignored classes to -100\n",
    "remapper = np.ones(3000, dtype=np.int32) * (-100)\n",
    "for i, x in enumerate([1,2,3,4,5,6,7,8,9,10,11,12,14,16,24,28,33,34,36,39]):\n",
    "    remapper[x] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_TFMS = [T.to_points_cloud(method='vertices', normals=False), \n",
    "            T.remap_labels(remapper=remapper, inplace=False),\n",
    "            T.colors_normalize(),\n",
    "            T.normalize_spatial(),\n",
    "           ]\n",
    "\n",
    "_scale = 20\n",
    "\n",
    "AUGS_TRAIN = [\n",
    "    T.noise_affine(amplitude=0.1),\n",
    "    T.flip_x(p=0.5),\n",
    "    T.scale(scale=_scale),\n",
    "    T.rotate_XY(),\n",
    "    \n",
    "    T.elastic(gran=6 * _scale // 50, mag=40 * _scale / 50),\n",
    "    T.elastic(gran=20 * _scale // 50, mag=160 * _scale / 50),\n",
    "    \n",
    "    T.specific_translate(full_scale=4096),\n",
    "    T.crop_points(low=0, high=4096),\n",
    "    T.colors_noise(amplitude=0.1),\n",
    "]\n",
    "\n",
    "AUGS_VALID = [\n",
    "    T.noise_affine(amplitude=0.1),\n",
    "    T.flip_x(p=0.5),\n",
    "    T.scale(scale=_scale),\n",
    "    T.rotate_XY(),\n",
    "\n",
    "    T.translate(offset=4096 / 2),\n",
    "    T.rand_translate(offset=(-2, 2, 3)),  # low, high, dimention\n",
    "    \n",
    "    T.specific_translate(full_scale=4096),\n",
    "    T.crop_points(low=0, high=4096),\n",
    "    T.colors_noise(amplitude=0.1),\n",
    "        \n",
    "    ]\n",
    "\n",
    "SPARSE_TFMS = [\n",
    "    T.merge_features(ones=False, colors=True, normals=False),\n",
    "    T.to_sparse_voxels(),\n",
    "]\n",
    "\n",
    "\n",
    "# reimplement to_torch\n",
    "def _to_torch(x):\n",
    "    x.coords \n",
    "    x.features\n",
    "    x.labels\n",
    "    \n",
    "    return x\n",
    "\n",
    "# to_torch = Transform(_to_torch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "functools.partial(<function SparseDataBunch.merge_fn at 0x7f2f1b5d9400>, keys_lists=['id', 'labels_raw', 'filtred_mask', 'random_seed', 'num_points'], separate_labels=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data import merge_fn\n",
    "merge_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(dataset_key):\n",
    "        \n",
    "    return  Compose(PRE_TFMS + AUGS_TRAIN + SPARSE_TFMS), Compose(PRE_TFMS + AUGS_VALID + SPARSE_TFMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataKeks creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df_list['train']#.head(96)\n",
    "val_df = df_list['valid']#.head(96)\n",
    "\n",
    "# now let's create DataKeks\n",
    "train_tfms, val_tfms = get_transforms(\"mesh\")\n",
    "\n",
    "train_dk = DataKek(df=train_df, reader_fn=reader_fn, transforms=train_tfms)\n",
    "val_dk = DataKek(df=val_df, reader_fn=reader_fn, transforms=val_tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: scene0000_00.merged\n",
      "coords                   shape: (81369, 3)            dtype: int64          min:       1618,  max:       3259,  mean: 2285.85127\n",
      "features                 shape: (81369, 3)            dtype: float32        min:   -1.01875,  max:    1.17132,  mean:   -0.10455\n",
      "x                        shape: (81369,)              dtype: int64          min:       1946,  max:       2116,  mean: 2030.13581\n",
      "y                        shape: (81369,)              dtype: int64          min:       3092,  max:       3259,  mean: 3178.46509\n",
      "z                        shape: (81369,)              dtype: int64          min:       1618,  max:       1699,  mean: 1648.95292\n",
      "labels                   shape: (81369,)              dtype: int64          min:       -100,  max:         17,  mean:  -48.51506\n",
      "voxels: 51995\n",
      "points / voxels: 1.5649389364361959\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "825c943523344e12894cafe24d49f1b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "b = train_dk[0]\n",
    "b.describe()\n",
    "b.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and DataLoaders\n",
    "#batch_size = 32\n",
    "#workers = \n",
    "\n",
    "train_dl = DataLoader(train_dk, batch_size=32, num_workers=8, shuffle=True, drop_last=True, collate_fn=merge_fn, pin_memory=False)\n",
    "val_dl = DataLoader(val_dk, batch_size=16, num_workers=8, shuffle=False, collate_fn=merge_fn, pin_memory=False)\n",
    "\n",
    "#train_dl = DataLoader(train_dk, batch_size=12, num_workers=8, shuffle=True, drop_last=True, collate_fn=merge_fn, pin_memory=False)\n",
    "#val_dl = DataLoader(val_dk, batch_size=2, num_workers=2, shuffle=False, collate_fn=merge_fn, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dl.pin_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dl.pin_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "for i, batch in enumerate(train_dl):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'coords': tensor([[3103, 1525, 1590,    0],\n",
       "         [3103, 1525, 1591,    0],\n",
       "         [3103, 1526, 1591,    0],\n",
       "         ...,\n",
       "         [  44, 3057, 3422,   31],\n",
       "         [  44, 3057, 3422,   31],\n",
       "         [  44, 3057, 3422,   31]]),\n",
       " 'features': tensor([[-0.0393, -0.1166, -0.2235],\n",
       "         [-0.0549, -0.1323, -0.2549],\n",
       "         [-0.0706, -0.1479, -0.3020],\n",
       "         ...,\n",
       "         [-0.4921, -0.5751, -0.4440],\n",
       "         [-0.4999, -0.5751, -0.4597],\n",
       "         [-0.2411, -0.3242, -0.1930]]),\n",
       " 'labels': tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       " 'id': ['scene0470_00.merged',\n",
       "  'scene0662_00.merged',\n",
       "  'scene0235_00.merged',\n",
       "  'scene0654_01.merged',\n",
       "  'scene0576_02.merged',\n",
       "  'scene0368_00.merged',\n",
       "  'scene0360_00.merged',\n",
       "  'scene0099_01.merged',\n",
       "  'scene0254_00.merged',\n",
       "  'scene0031_01.merged',\n",
       "  'scene0511_01.merged',\n",
       "  'scene0150_01.merged',\n",
       "  'scene0121_02.merged',\n",
       "  'scene0501_01.merged',\n",
       "  'scene0128_00.merged',\n",
       "  'scene0369_02.merged',\n",
       "  'scene0649_00.merged',\n",
       "  'scene0569_00.merged',\n",
       "  'scene0449_02.merged',\n",
       "  'scene0673_00.merged',\n",
       "  'scene0380_01.merged',\n",
       "  'scene0302_00.merged',\n",
       "  'scene0199_00.merged',\n",
       "  'scene0601_00.merged',\n",
       "  'scene0399_01.merged',\n",
       "  'scene0444_00.merged',\n",
       "  'scene0029_01.merged',\n",
       "  'scene0348_01.merged',\n",
       "  'scene0563_00.merged',\n",
       "  'scene0166_00.merged',\n",
       "  'scene0210_00.merged',\n",
       "  'scene0582_01.merged'],\n",
       " 'labels_raw': [array([0, 0, 0, 0, ..., 0, 4, 4, 4], dtype=int32),\n",
       "  array([-100, -100, -100, -100, ...,    0,    0,    0, -100], dtype=int32),\n",
       "  array([-100, -100, -100, -100, ..., -100, -100, -100, -100], dtype=int32),\n",
       "  array([-100, -100, -100, -100, ..., -100, -100, -100, -100], dtype=int32),\n",
       "  array([  17, -100, -100, -100, ..., -100, -100, -100, -100], dtype=int32),\n",
       "  array([1, 1, 1, 1, ..., 0, 0, 0, 0], dtype=int32),\n",
       "  array([0, 0, 2, 0, ..., 0, 0, 0, 0], dtype=int32),\n",
       "  array([   0,    0,    0,    0, ..., -100, -100, -100, -100], dtype=int32),\n",
       "  array([0, 0, 0, 0, ..., 0, 0, 0, 0], dtype=int32),\n",
       "  array([   2,    2,    2,    2, ..., -100, -100, -100, -100], dtype=int32),\n",
       "  array([-100, -100, -100, -100, ..., -100, -100, -100, -100], dtype=int32),\n",
       "  array([-100, -100,    2,    2, ...,    0,    0,    0,    0], dtype=int32),\n",
       "  array([-100, -100, -100, -100, ..., -100, -100, -100, -100], dtype=int32),\n",
       "  array([-100, -100, -100, -100, ..., -100, -100, -100, -100], dtype=int32),\n",
       "  array([   2,    2,    2,    2, ..., -100, -100, -100, -100], dtype=int32),\n",
       "  array([2, 2, 2, 2, ..., 0, 0, 0, 0], dtype=int32),\n",
       "  array([-100, -100, -100, -100, ...,    0,    0,    0, -100], dtype=int32),\n",
       "  array([-100, -100, -100, -100, ...,    0,    0,    0,    0], dtype=int32),\n",
       "  array([-100, -100, -100, -100, ..., -100, -100, -100, -100], dtype=int32),\n",
       "  array([-100, -100, -100, -100, ..., -100,    0,    0,    0], dtype=int32),\n",
       "  array([-100, -100, -100, -100, ..., -100, -100, -100, -100], dtype=int32),\n",
       "  array([2, 2, 2, 2, ..., 0, 0, 0, 0], dtype=int32),\n",
       "  array([2, 2, 2, 2, ..., 0, 0, 0, 0], dtype=int32),\n",
       "  array([-100, -100, -100, -100, ...,    0,    0,    0,    0], dtype=int32),\n",
       "  array([-100, -100, -100, -100, ...,    2,    2,    2,    2], dtype=int32),\n",
       "  array([6, 6, 6, 6, ..., 0, 0, 0, 0], dtype=int32),\n",
       "  array([-100, -100, -100, -100, ..., -100,    0,    0,    0], dtype=int32),\n",
       "  array([-100, -100, -100, -100, ...,    0,    0,    0,    0], dtype=int32),\n",
       "  array([-100, -100, -100, -100, ..., -100, -100, -100, -100], dtype=int32),\n",
       "  array([   2, -100, -100, -100, ..., -100, -100,    0,    0], dtype=int32),\n",
       "  array([0, 0, 6, 6, ..., 2, 2, 2, 2], dtype=int32),\n",
       "  array([7, 7, 7, 7, ..., 0, 0, 0, 0], dtype=int32)],\n",
       " 'filtred_mask': [array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True]),\n",
       "  array([ True,  True,  True,  True, ...,  True,  True,  True,  True])],\n",
       " 'random_seed': ['182479695_340',\n",
       "  '1292740222_264',\n",
       "  '1741434149_312',\n",
       "  '2823988168_140',\n",
       "  '649861767_228',\n",
       "  '2941211774_112',\n",
       "  '3379533227_440',\n",
       "  '296525474_80',\n",
       "  '207020725_440',\n",
       "  '497598068_40',\n",
       "  '3168221195_300',\n",
       "  '2881255566_336',\n",
       "  '806421572_224',\n",
       "  '1119037316_116',\n",
       "  '2052385399_276',\n",
       "  '1697349261_388',\n",
       "  '3481073715_56',\n",
       "  '225097249_100',\n",
       "  '157631320_492',\n",
       "  '100342_396',\n",
       "  '1848795919_364',\n",
       "  '2102817586_576',\n",
       "  '2361204992_576',\n",
       "  '3008858478_444',\n",
       "  '2221092942_92',\n",
       "  '3021209329_532',\n",
       "  '1617108327_108',\n",
       "  '3246590741_108',\n",
       "  '1593665656_304',\n",
       "  '3184915984_348',\n",
       "  '598897525_52',\n",
       "  '940621256_364'],\n",
       " 'num_points': [67465,\n",
       "  46821,\n",
       "  191926,\n",
       "  187822,\n",
       "  130258,\n",
       "  100591,\n",
       "  81298,\n",
       "  170918,\n",
       "  119777,\n",
       "  235122,\n",
       "  83484,\n",
       "  77935,\n",
       "  98699,\n",
       "  111898,\n",
       "  108008,\n",
       "  153044,\n",
       "  70554,\n",
       "  142057,\n",
       "  59822,\n",
       "  254321,\n",
       "  164540,\n",
       "  292241,\n",
       "  170183,\n",
       "  209655,\n",
       "  84554,\n",
       "  25481,\n",
       "  41212,\n",
       "  71272,\n",
       "  129766,\n",
       "  225624,\n",
       "  114103,\n",
       "  166400]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4186851, 4186851)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch['coords']), sum(batch['num_points'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseModelConfig;\n",
       "   spatial_size: 4096\n",
       "   dimension: 3\n",
       "   block_reps: 1\n",
       "   m: 16\n",
       "   num_planes: [16, 32, 48, 64, 80, 96, 112]\n",
       "   residual_blocks: False\n",
       "   num_classes: 20\n",
       "   num_input_features: 3\n",
       "   mode: 4\n",
       "   downsample: [2, 2]\n",
       "   bias: False"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spatial_size  is full_scale\n",
    "model_config = SparseModelConfig(spatial_size=4096, num_classes=20, num_input_features=3, mode=4,\n",
    "                                 m=16, num_planes_coeffs=[1, 2, 3, 4, 5, 6, 7])\n",
    "model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        C = cfg\n",
    "        nn.Module.__init__(self)\n",
    "        self.sparseModel = scn.Sequential(\n",
    "            scn.InputLayer(C.dimension, C.spatial_size, mode=C.mode),\n",
    "            scn.SubmanifoldConvolution(C.dimension, nIn=C.num_input_features, nOut=C.m, filter_size=3, bias=C.bias),\n",
    "            scn.UNet(C.dimension, C.block_reps, C.num_planes, residual_blocks=C.residual_blocks, downsample=C.downsample),\n",
    "            scn.BatchNormReLU(C.m),\n",
    "            scn.OutputLayer(C.dimension),\n",
    "        )\n",
    "        self.linear = nn.Linear(C.m, C.num_classes)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        x = [xb['coords'], xb['features']]\n",
    "        x = self.sparseModel(x)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "model = Model(model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the three whales of your pipelane are: the data, the model and the loss (hi, Jeremy)\n",
    "\n",
    "# the data is represented in Kekas by DataOwner. It is a namedtuple with three fields:\n",
    "# 'train_dl', 'val_dl', 'test_dl'\n",
    "# For training process we will need at least two of them, and we can skip 'test_dl' for now\n",
    "# so we will initialize it with `None` value.\n",
    "dataowner = DataOwner(train_dl, val_dl, None)\n",
    "\n",
    "# model is just a pytorch nn.Module, that we created vefore\n",
    "#model = Net(num_classes=2)\n",
    "\n",
    "# loss or criterion is also a pytorch nn.Module. For multiloss scenarios it can be a list of nn.Modules\n",
    "# for our simple example let's use the standart cross entopy criterion\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also we need to specify, what model will do with each batch of data on each iteration\n",
    "# We should define a `step_fn` function\n",
    "# The code below repeats a `keker.default_step_fn` code to provide you with a concept of step function\n",
    "\n",
    "def step_fn(model: torch.nn.Module,\n",
    "            batch: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Determine what your model will do with your data.\n",
    "\n",
    "    Args:\n",
    "        model: the pytorch module to pass input in\n",
    "        batch: the batch of data from the DataLoader\n",
    "\n",
    "    Returns:\n",
    "        The models forward pass results\n",
    "    \"\"\"\n",
    "    \n",
    "    # you could define here whatever logic you want\n",
    "    inp = batch  # here we get an \"image\" from our dataset\n",
    "    return model(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "from fastai.torch_core import add_metrics\n",
    "from fastai_sparse.metrics import confusion_matrix, iou_per_class_from_cm\n",
    "\n",
    "from collections import defaultdict\n",
    "from kekas.utils import get_opt_lr, get_pbar, DotDict, to_numpy\n",
    "\n",
    "\n",
    "class IouMeanFiltred(Callback):\n",
    "    \"\"\"\n",
    "    Calc IoU by classes, filter incorrect classes (-100), then mean.\n",
    "    \"\"\"\n",
    "\n",
    "    _order = -19  # Needs to run before the recorder\n",
    "\n",
    "    def __init__(self, target_key: str, preds_key: str, n_classes, name='iouf', epsilon=sys.float_info.epsilon, **kwargs):\n",
    "        self.target_key = target_key\n",
    "        self.preds_key = preds_key\n",
    "        self.n_classes = n_classes\n",
    "        self.epsilon = epsilon\n",
    "        self.name = name\n",
    "        \n",
    "        # for kekas\n",
    "        self.pbar_metrics = None\n",
    "\n",
    "        #super().__init__(learn, **kwargs)\n",
    "\n",
    "    #def append_metrics_names(self, names):\n",
    "    #    recorder = self.learn.recorder\n",
    "    #    if not hasattr(recorder, '_added_met_names'):\n",
    "    #        recorder._added_met_names = []\n",
    "    #    recorder._added_met_names += names\n",
    "\n",
    "    #def on_train_begin(self, **kwargs):\n",
    "    #    #self.append_metrics_names(self.names)\n",
    "        \n",
    "\n",
    "    #def on_epoch_begin(self, **kwargs):\n",
    "    def on_epoch_begin(self, epoch: int, epochs: int, state: DotDict) -> None:\n",
    "        \n",
    "        #print(\"state.core.mode:\", state.core.mode)\n",
    "        self._d = {}\n",
    "\n",
    "        d = {}\n",
    "        if state.core.mode == 'train':\n",
    "            self._d['train'] = d\n",
    "        elif state.core.mode == 'val':\n",
    "            self._d['valid'] = d\n",
    "\n",
    "        if state.core.mode in ['train', 'val']:\n",
    "            d['runned'] = False\n",
    "            d['cm'] = np.zeros(shape=(self.n_classes, self.n_classes), dtype=np.uint64)\n",
    "            \n",
    "        # for kekas\n",
    "        self.pbar_metrics = defaultdict(float)\n",
    "\n",
    "    #def on_batch_end(self, last_output, last_target, last_input, train, **kwargs):\n",
    "    def on_batch_end(self, i: int, state: DotDict) -> None:\n",
    "        \n",
    "        train = (state.core.mode == 'train')\n",
    "        \n",
    "        #print(\"state.core.mode:\", state.core.mode)\n",
    "        #print(\"state.core.do_log:\", state.core.do_log)\n",
    "\n",
    "        last_target = state.core.batch[self.target_key]\n",
    "        last_input = state.core.batch\n",
    "        last_output = state.core.out[self.preds_key]\n",
    "\n",
    "        if train:\n",
    "            d = self._d['train']\n",
    "        else:\n",
    "            d = self._d['valid']\n",
    "\n",
    "        #predictions = last_output.detach().cpu().numpy()\n",
    "        predictions = last_output\n",
    "       \n",
    "        \n",
    "        xb = last_input\n",
    "\n",
    "        num_points_actual_cumsum = np.cumsum([0] + xb['num_points'])\n",
    "        \n",
    "        cm_batch = np.zeros(shape=(self.n_classes, self.n_classes), dtype=np.uint64)\n",
    "\n",
    "        # for each example in the batch extract prediction, argmax, fill omitted by 0-label class (bug), and store\n",
    "        for k in range(len(xb['id'])):\n",
    "            # actual number of points\n",
    "            # num_points = xb['num_points'][k]     # equal len(y)\n",
    "\n",
    "            labels_raw = xb['labels_raw'][k]\n",
    "            filtred_mask = xb['filtred_mask'][k]\n",
    "            num_points_raw = len(labels_raw)\n",
    "\n",
    "            # extract prediction of example\n",
    "            start = num_points_actual_cumsum[k]\n",
    "            end = num_points_actual_cumsum[k + 1]\n",
    "            example_preds_actual = predictions[start:end]\n",
    "\n",
    "            # Use argmax now\n",
    "            # form target prediction\n",
    "            example_y_pred = np.ones(shape=(num_points_raw), dtype=np.int32) * (self.n_classes - 1)\n",
    "\n",
    "            # fill preds for the points that net outputs, eg 800, than 200 will be remains with zeros\n",
    "            example_y_pred[filtred_mask] = example_preds_actual.argmax(1)\n",
    "\n",
    "            # filter\n",
    "            indexer = labels_raw >= 0\n",
    "\n",
    "            # accumulate cm of example\n",
    "            y_pred = example_y_pred[indexer]\n",
    "            y_true = labels_raw[indexer]\n",
    "            if len(y_pred) == 0:\n",
    "                warnings.warn(f\"Wrong example is found: all `labels_raw` < 0. Id={xb['id'][k]}\")\n",
    "            else:\n",
    "                cm = confusion_matrix(y_pred, y_true, self.n_classes)\n",
    "                #d['cm'] += cm\n",
    "                cm_batch += cm\n",
    "                d['runned'] = True\n",
    "                \n",
    "        d['cm'] += cm_batch\n",
    "        #_iou_per_class = iou_per_class_from_cm(cm_batch)\n",
    "        #_iou = np.mean(_iou_per_class)\n",
    "\n",
    "        #print(state.core.mode, _iou, len(xb['id']))\n",
    "                              \n",
    "        #if state.core.mode == \"val\":            \n",
    "        #    self.pbar_metrics[self.name] = _iou\n",
    "\n",
    "        #if state.core.mode != \"test\" and state.core.do_log:\n",
    "        ## state.core.metrics[state.core.mode][\"loss\"] = float(to_numpy(state.core.loss))\n",
    "        #    state.core.metrics[state.core.mode][self.name] = _iou\n",
    "      \n",
    "\n",
    "    #def on_epoch_end(self, last_metrics, **kwargs):\n",
    "    def on_epoch_end(self, epoch: int, state: DotDict) -> None:\n",
    "\n",
    "        #print(\"on_epoch_end: state.core.mode:\", state.core.mode)\n",
    "                              \n",
    "        d = None\n",
    "        if state.core.mode == 'train':\n",
    "            d = self._d['train']\n",
    "        elif state.core.mode == 'val':\n",
    "            d = self._d['valid']\n",
    "\n",
    "        if d is not None:\n",
    "            if d['runned']:\n",
    "                cm = d['cm']\n",
    "                d['iou_per_class'] = iou_per_class_from_cm(cm)\n",
    "                d['iou'] = np.mean(d['iou_per_class'])\n",
    "            else:\n",
    "                d['cm'] = None\n",
    "                d['iou_per_class'] = None\n",
    "                d['iou'] = 0\n",
    "                                      \n",
    "            self.pbar_metrics[state.core.mode + \"_\" + self.name] = d['iou']\n",
    "\n",
    "            if state.core.epoch_metrics is None:\n",
    "                  state.core.epoch_metrics = self.pbar_metrics.copy()\n",
    "            else:\n",
    "                state.core.epoch_metrics.update(self.pbar_metrics)\n",
    "            #print(state.core.epoch_metrics)\n",
    "\n",
    "        \n",
    "                              \n",
    "                              \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "keker_callbacks = []\n",
    "keker_callbacks.append(IouMeanFiltred(target_key='labels', preds_key='preds', n_classes=model_config.num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# previous preparations was mostly out of scope of Kekas library (except DataKeks creation)\n",
    "# Now let's dive into kekas a little bit\n",
    "\n",
    "# firstly, we create a Keker - the core Kekas class, that provides all the keks for your pipeline\n",
    "keker = Keker(model=model,\n",
    "              dataowner=dataowner,\n",
    "              criterion=criterion,\n",
    "              step_fn=step_fn,                    # previosly defined step function\n",
    "              target_key=\"labels\",                # remember, we defined it in the reader_fn for DataKek?              \n",
    "              opt=torch.optim.SGD,                # optimizer class. if note specifiyng, \n",
    "                                                  # an SGD is using by default\n",
    "              opt_params={\"weight_decay\": params['wd']},  # optimizer kwargs in dict format (optional too)\n",
    "              callbacks=keker_callbacks\n",
    "             )\n",
    "\n",
    "# Actually, there are a lot of params for kekers, but this out of scope of this example\n",
    "# you can read about them in Keker's docstring (but who really reads the docs, huh?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before the start of the finetuning procedure let's freeeze all the layers except the last one - the head\n",
    "# the `freeze` method is mostly inspired (or stolen) from fastai\n",
    "# but you should define a model's attribute to deal with\n",
    "# for example, our model is actually model.net, so we need to specify the 'net' attr\n",
    "# also this method does not freezes batchnorm layers by default. To change this set `freeze_bn=True`\n",
    "\n",
    "#keker.freeze(model_attr=\"net\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 10)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataowner.train_dl), len(dataowner.val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/384:   0% 0/32 [00:00<?, ?it/s]train 0.01077241164798125 32\n",
      "Epoch 1/384:   3% 1/32 [00:39<20:16, 39.24s/it, loss=2.9214]train 0.011896222123155931 32\n",
      "Epoch 1/384:   6% 2/32 [00:48<15:11, 30.40s/it, loss=2.9216]train 0.012815994464983268 32\n",
      "Epoch 1/384:   9% 3/32 [00:56<11:23, 23.58s/it, loss=2.9204]train 0.01266047288314219 32\n",
      "Epoch 1/384:  12% 4/32 [01:02<08:32, 18.29s/it, loss=2.9184]train 0.015023065623966311 32\n",
      "Epoch 1/384:  16% 5/32 [01:08<06:32, 14.52s/it, loss=2.9145]train 0.01567386898698736 32\n",
      "Epoch 1/384:  19% 6/32 [01:14<05:12, 12.01s/it, loss=2.9067]train 0.022903120340760936 32\n",
      "Epoch 1/384:  22% 7/32 [01:20<04:18, 10.34s/it, loss=2.8947]train 0.028525945365967788 32\n",
      "Epoch 1/384:  25% 8/32 [01:25<03:29,  8.71s/it, loss=2.8771]train 0.0345662647029311 32\n",
      "Epoch 1/384:  28% 9/32 [01:31<02:57,  7.74s/it, loss=2.8545]train 0.040246828614136164 32\n",
      "Epoch 1/384:  31% 10/32 [01:38<02:45,  7.53s/it, loss=2.8230]train 0.039347718969231074 32\n",
      "Epoch 1/384:  34% 11/32 [01:44<02:28,  7.08s/it, loss=2.7869]train 0.04304209398689497 32\n",
      "Epoch 1/384:  38% 12/32 [01:48<02:05,  6.30s/it, loss=2.7409]train 0.04414804574627175 32\n",
      "Epoch 1/384:  41% 13/32 [01:53<01:48,  5.72s/it, loss=2.6881]train 0.041371101072174156 32\n",
      "Epoch 1/384:  44% 14/32 [01:57<01:35,  5.33s/it, loss=2.6240]train 0.04417704941321868 32\n",
      "Epoch 1/384:  47% 15/32 [02:02<01:27,  5.17s/it, loss=2.5572]train 0.09405676420052256 32\n",
      "Epoch 1/384:  50% 16/32 [02:06<01:19,  4.97s/it, loss=2.4849]train 0.041533086563408 32\n",
      "Epoch 1/384:  53% 17/32 [02:12<01:16,  5.07s/it, loss=2.4299]train 0.0957948210988839 32\n",
      "Epoch 1/384:  56% 18/32 [02:17<01:10,  5.05s/it, loss=2.3596]train 0.04917811329368807 32\n",
      "Epoch 1/384:  59% 19/32 [02:21<01:01,  4.75s/it, loss=2.2804]train 0.14967561123069933 32\n",
      "Epoch 1/384:  62% 20/32 [02:24<00:51,  4.28s/it, loss=2.2287]train 0.05477577244127313 32\n",
      "Epoch 1/384:  66% 21/32 [02:28<00:46,  4.22s/it, loss=2.1759]train 0.05272501378370491 32\n",
      "Epoch 1/384:  69% 22/32 [02:32<00:41,  4.16s/it, loss=2.1274]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roma/.virtualenvs/aseg_torch1/lib/python3.6/site-packages/ipykernel_launcher.py:113: UserWarning:\n",
      "\n",
      "Wrong example is found: all `labels_raw` < 0. Id=scene0509_00.merged\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.10333149693153754 32\n",
      "Epoch 1/384:  72% 23/32 [02:38<00:41,  4.59s/it, loss=2.1045]train 0.10633436517263468 32\n",
      "Epoch 1/384:  75% 24/32 [02:41<00:34,  4.32s/it, loss=2.0663]train 0.11038189611746343 32\n",
      "Epoch 1/384:  78% 25/32 [02:45<00:29,  4.24s/it, loss=2.0286]train 0.06233302504444849 32\n",
      "Epoch 1/384:  81% 26/32 [02:50<00:25,  4.32s/it, loss=1.9894]train 0.059082314896209034 32\n",
      "Epoch 1/384:  84% 27/32 [02:54<00:20,  4.12s/it, loss=1.9619]train 0.06015646444365739 32\n",
      "Epoch 1/384:  88% 28/32 [02:57<00:15,  3.98s/it, loss=1.9324]train 0.1073027511758025 32\n",
      "Epoch 1/384:  91% 29/32 [03:01<00:11,  3.86s/it, loss=1.9241]train 0.11193829119800935 32\n",
      "Epoch 1/384:  94% 30/32 [03:05<00:07,  3.84s/it, loss=1.9076]train 0.11001798500497036 32\n",
      "Epoch 1/384:  97% 31/32 [03:09<00:03,  3.87s/it, loss=1.8918]train 0.06014804943136427 32\n",
      "Epoch 1/384: 100% 32/32 [03:13<00:00,  4.07s/it, loss=1.8755]val 0.3075522285137244 16\n",
      "val 0.2209215643360186 16\n",
      "val 0.3095796066555487 16\n",
      "val 0.16234222439363777 16\n",
      "val 0.21706682588663853 16\n",
      "val 0.316710205537318 16\n",
      "val 0.16910513947775144 16\n",
      "val 0.2674886820039176 16\n",
      "val 0.15855320601324635 16\n",
      "val 0.16422568796277287 12\n",
      "Epoch 1/384: 100% 32/32 [03:31<00:00,  4.07s/it, loss=1.8755, train_iouf=0.0455, iouf=0.1642, val_iouf=0.0644, val_loss=1.6414]\n",
      "Epoch 2/384:   0% 0/32 [00:00<?, ?it/s]train 0.06138560329291343 32\n",
      "Epoch 2/384:   3% 1/32 [00:39<20:24, 39.51s/it, loss=1.6032]train 0.11126853054965938 32\n",
      "Epoch 2/384:   6% 2/32 [00:47<15:03, 30.11s/it, loss=1.6094]train 0.11030850503609302 32\n",
      "Epoch 2/384:   9% 3/32 [00:56<11:31, 23.84s/it, loss=1.6139]train 0.10570900850776543 32\n",
      "Epoch 2/384:  12% 4/32 [01:04<08:47, 18.84s/it, loss=1.6266]train 0.059280374128829104 32\n",
      "Epoch 2/384:  16% 5/32 [01:10<06:47, 15.08s/it, loss=1.6150]train 0.060667888620289476 32\n",
      "Epoch 2/384:  19% 6/32 [01:15<05:15, 12.14s/it, loss=1.6134]train 0.1138889105690832 32\n",
      "Epoch 2/384:  22% 7/32 [01:20<04:11, 10.07s/it, loss=1.5994]train 0.06353781122538034 32\n",
      "Epoch 2/384:  25% 8/32 [01:26<03:29,  8.75s/it, loss=1.5812]train 0.16613606593406405 32\n",
      "Epoch 2/384:  28% 9/32 [01:31<02:56,  7.67s/it, loss=1.5555]train 0.06097981731460467 32\n",
      "Epoch 2/384:  31% 10/32 [01:36<02:29,  6.78s/it, loss=1.5489]train 0.06242852505368292 32\n",
      "Epoch 2/384:  34% 11/32 [01:41<02:08,  6.12s/it, loss=1.5330]train 0.1602380088944271 32\n",
      "Epoch 2/384:  38% 12/32 [01:45<01:49,  5.50s/it, loss=1.5240]train 0.05562162956309301 32\n",
      "Epoch 2/384:  41% 13/32 [01:50<01:43,  5.43s/it, loss=1.5202]train 0.057051688685571075 32\n",
      "Epoch 2/384:  44% 14/32 [01:55<01:38,  5.49s/it, loss=1.5091]train 0.09873607324701038 32\n",
      "Epoch 2/384:  47% 15/32 [02:01<01:31,  5.36s/it, loss=1.5167]train 0.051399634949613436 32\n",
      "Epoch 2/384:  50% 16/32 [02:05<01:23,  5.24s/it, loss=1.5209]train 0.10413872031833993 32\n",
      "Epoch 2/384:  53% 17/32 [02:10<01:16,  5.11s/it, loss=1.5108]train 0.1038904907377699 32\n",
      "Epoch 2/384:  56% 18/32 [02:15<01:08,  4.88s/it, loss=1.5108]train 0.10915361840029074 32\n",
      "Epoch 2/384:  59% 19/32 [02:18<00:58,  4.48s/it, loss=1.5031]train 0.057614365646397936 32\n",
      "Epoch 2/384:  62% 20/32 [02:22<00:50,  4.22s/it, loss=1.5188]train 0.0631989282512476 32\n",
      "Epoch 2/384:  66% 21/32 [02:26<00:44,  4.09s/it, loss=1.5021]train 0.06403125486352922 32\n",
      "Epoch 2/384:  69% 22/32 [02:30<00:42,  4.27s/it, loss=1.4869]train 0.21740215107526611 32\n",
      "Epoch 2/384:  72% 23/32 [02:34<00:37,  4.17s/it, loss=1.4593]train 0.11231847075724266 32\n",
      "Epoch 2/384:  75% 24/32 [02:39<00:33,  4.25s/it, loss=1.4499]train 0.11474871711737908 32\n",
      "Epoch 2/384:  78% 25/32 [02:42<00:28,  4.03s/it, loss=1.4353]train 0.11006086642862804 32\n",
      "Epoch 2/384:  81% 26/32 [02:46<00:23,  3.98s/it, loss=1.4456]train 0.11545529226114852 32\n",
      "Epoch 2/384:  84% 27/32 [02:50<00:20,  4.08s/it, loss=1.4306]train 0.11825405285704715 32\n",
      "Epoch 2/384:  88% 28/32 [02:55<00:16,  4.16s/it, loss=1.4088]train 0.1644107964475327 32\n",
      "Epoch 2/384:  91% 29/32 [02:59<00:12,  4.12s/it, loss=1.3976]train 0.06468995515999716 32\n",
      "Epoch 2/384:  94% 30/32 [03:03<00:08,  4.14s/it, loss=1.3885]train 0.06025812048557898 32\n",
      "Epoch 2/384:  97% 31/32 [03:07<00:04,  4.03s/it, loss=1.4045]train 0.06414817170388856 32\n",
      "Epoch 2/384: 100% 32/32 [03:11<00:00,  4.07s/it, loss=1.3995]val 0.3143318182145355 16\n",
      "val 0.2279556777534904 16\n",
      "val 0.3126638025766685 16\n",
      "val 0.16722357379709554 16\n",
      "val 0.22289251859921025 16\n",
      "val 0.32195185216223027 16\n",
      "val 0.17582881032650238 16\n",
      "val 0.2741085705609337 16\n",
      "val 0.16599956958674594 16\n",
      "val 0.1696460982554407 12\n",
      "Epoch 2/384: 100% 32/32 [03:28<00:00,  4.07s/it, loss=1.3995, train_iouf=0.0606, iouf=0.1696, val_iouf=0.0703, val_loss=1.2563]\n",
      "Epoch 3/384:   0% 0/32 [00:00<?, ?it/s]train 0.11242016515998347 32\n",
      "Epoch 3/384:   3% 1/32 [00:32<16:38, 32.22s/it, loss=1.4071]train 0.06848833838561438 32\n",
      "Epoch 3/384:   6% 2/32 [00:40<12:34, 25.16s/it, loss=1.3860]train 0.2672406585279565 32\n",
      "Epoch 3/384:   9% 3/32 [00:47<09:26, 19.54s/it, loss=1.3703]train 0.11836293192973313 32\n",
      "Epoch 3/384:  12% 4/32 [00:57<07:52, 16.87s/it, loss=1.3510]train 0.06765138638753644 32\n",
      "Epoch 3/384:  16% 5/32 [01:03<06:05, 13.55s/it, loss=1.3365]train 0.11701280817421858 32\n",
      "Epoch 3/384:  19% 6/32 [01:10<04:58, 11.48s/it, loss=1.3251]train 0.06917562761792825 32\n",
      "Epoch 3/384:  22% 7/32 [01:16<04:09,  9.97s/it, loss=1.3089]train 0.06769000609324966 32\n",
      "Epoch 3/384:  25% 8/32 [01:23<03:33,  8.91s/it, loss=1.3040]train 0.11965093629585581 32\n",
      "Epoch 3/384:  28% 9/32 [01:29<03:04,  8.01s/it, loss=1.2847]train 0.17070886492543447 32\n",
      "Epoch 3/384:  31% 10/32 [01:33<02:32,  6.95s/it, loss=1.2688]train 0.06780781423665905 32\n",
      "Epoch 3/384:  34% 11/32 [01:38<02:10,  6.22s/it, loss=1.2700]train 0.11847274417131692 32\n",
      "Epoch 3/384:  38% 12/32 [01:43<01:58,  5.91s/it, loss=1.2656]train 0.1695411935917847 32\n",
      "Epoch 3/384:  41% 13/32 [01:48<01:46,  5.60s/it, loss=1.2586]train 0.06641742458330756 32\n",
      "Epoch 3/384:  44% 14/32 [01:53<01:40,  5.60s/it, loss=1.2636]train 0.0664788079842132 32\n",
      "Epoch 3/384:  47% 15/32 [01:58<01:30,  5.34s/it, loss=1.2713]train 0.11774337295521373 32\n",
      "Epoch 3/384:  50% 16/32 [02:03<01:23,  5.25s/it, loss=1.2668]train 0.11708902522069439 32\n",
      "Epoch 3/384:  53% 17/32 [02:08<01:14,  5.00s/it, loss=1.2584]train 0.06451078491816224 32\n",
      "Epoch 3/384:  56% 18/32 [02:11<01:05,  4.65s/it, loss=1.2710]train 0.166080192323452 32\n",
      "Epoch 3/384:  59% 19/32 [02:15<00:55,  4.28s/it, loss=1.2730]train 0.06602912773123856 32\n",
      "Epoch 3/384:  62% 20/32 [02:20<00:52,  4.41s/it, loss=1.2698]train 0.11739518999022472 32\n",
      "Epoch 3/384:  66% 21/32 [02:24<00:47,  4.32s/it, loss=1.2643]train 0.11790786889561782 32\n",
      "Epoch 3/384:  69% 22/32 [02:28<00:41,  4.20s/it, loss=1.2525]train 0.17292218336181717 32\n",
      "Epoch 3/384:  72% 23/32 [02:31<00:36,  4.07s/it, loss=1.2317]train 0.06758126123191947 32\n",
      "Epoch 3/384:  75% 24/32 [02:35<00:32,  4.05s/it, loss=1.2363]train 0.12037235668990429 32\n",
      "Epoch 3/384:  78% 25/32 [02:40<00:28,  4.14s/it, loss=1.2294]train 0.1222454717406742 32\n",
      "Epoch 3/384:  81% 26/32 [02:44<00:25,  4.22s/it, loss=1.2185]train 0.06678541690437916 32\n",
      "Epoch 3/384:  84% 27/32 [02:48<00:20,  4.12s/it, loss=1.2284]train 0.07335692982609933 32\n",
      "Epoch 3/384:  88% 28/32 [02:52<00:16,  4.09s/it, loss=1.2092]train 0.07271476222817852 32\n",
      "Epoch 3/384:  91% 29/32 [02:56<00:12,  4.13s/it, loss=1.1984]train 0.12212663624540947 32\n",
      "Epoch 3/384:  94% 30/32 [03:00<00:08,  4.14s/it, loss=1.1880]train 0.1266576426290126 32\n",
      "Epoch 3/384:  97% 31/32 [03:04<00:04,  4.03s/it, loss=1.1667]train 0.12174422933104076 32\n",
      "Epoch 3/384: 100% 32/32 [03:09<00:00,  4.22s/it, loss=1.1596]val 0.3211536145910826 16\n",
      "val 0.23151087010084642 16\n",
      "val 0.3177412134030715 16\n",
      "val 0.1730227772398709 16\n",
      "val 0.22619707448966894 16\n",
      "val 0.328313869860349 16\n",
      "val 0.17884881537108738 16\n",
      "val 0.2780862443098801 16\n",
      "val 0.17191525731452786 16\n",
      "val 0.17454614445767638 12\n",
      "Epoch 3/384: 100% 32/32 [03:26<00:00,  4.22s/it, loss=1.1596, train_iouf=0.0687, iouf=0.1745, val_iouf=0.0753, val_loss=1.0639]\n",
      "Epoch 4/384:   0% 0/32 [00:00<?, ?it/s]train 0.17201106815011794 32\n",
      "Epoch 4/384:   3% 1/32 [00:31<16:14, 31.42s/it, loss=1.1153]train 0.11940065944846742 32\n",
      "Epoch 4/384:   6% 2/32 [00:41<12:26, 24.89s/it, loss=1.1215]train 0.17499175024447244 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/384:   9% 3/32 [00:49<09:38, 19.94s/it, loss=1.1079]train 0.07346416822228924 32\n",
      "Epoch 4/384:  12% 4/32 [00:58<07:46, 16.66s/it, loss=1.1017]train 0.12149620944227586 32\n",
      "Epoch 4/384:  16% 5/32 [01:04<06:05, 13.55s/it, loss=1.1047]train 0.07389219522117904 32\n",
      "Epoch 4/384:  19% 6/32 [01:13<05:11, 11.97s/it, loss=1.0965]train 0.17528431705806385 32\n",
      "Epoch 4/384:  22% 7/32 [01:19<04:21, 10.44s/it, loss=1.0874]train 0.07101438754695523 32\n",
      "Epoch 4/384:  25% 8/32 [01:26<03:46,  9.42s/it, loss=1.0963]train 0.07349639368638625 32\n",
      "Epoch 4/384:  28% 9/32 [01:32<03:08,  8.18s/it, loss=1.0940]train 0.07039132383192204 32\n",
      "Epoch 4/384:  31% 10/32 [01:36<02:36,  7.10s/it, loss=1.1053]train 0.07401877648956683 32\n",
      "Epoch 4/384:  34% 11/32 [01:41<02:13,  6.37s/it, loss=1.1011]train 0.17225234048576635 32\n",
      "Epoch 4/384:  38% 12/32 [01:46<01:57,  5.88s/it, loss=1.0982]train 0.07257258898317212 32\n",
      "Epoch 4/384:  41% 13/32 [01:53<01:58,  6.24s/it, loss=1.0957]train 0.12435961487705308 32\n",
      "Epoch 4/384:  44% 14/32 [01:59<01:50,  6.11s/it, loss=1.0886]train 0.17322400071823257 32\n",
      "Epoch 4/384:  47% 15/32 [02:03<01:37,  5.74s/it, loss=1.0892]train 0.17643452019381461 32\n",
      "Epoch 4/384:  50% 16/32 [02:08<01:27,  5.46s/it, loss=1.0748]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-b045de9a4fe0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mmax_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max_lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mdiv_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincrease_fraction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                     logdir=logdir)\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/aseg_torch1/lib/python3.6/site-packages/kekas/keker.py\u001b[0m in \u001b[0;36mkek_one_cycle\u001b[0;34m(self, max_lr, cycle_len, momentum_range, div_factor, increase_fraction, opt, opt_params, logdir, cp_saver_params, early_stop_params)\u001b[0m\n\u001b[1;32m    355\u001b[0m                      \u001b[0mlogdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogdir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m                      \u001b[0mcp_saver_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcp_saver_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m                      early_stop_params=early_stop_params)\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;31m# set old callbacks without OneCycle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/aseg_torch1/lib/python3.6/site-packages/kekas/keker.py\u001b[0m in \u001b[0;36mkek\u001b[0;34m(self, lr, epochs, skip_val, opt, opt_params, sched, sched_params, stop_iter, logdir, cp_saver_params, early_stop_params)\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mskip_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/aseg_torch1/lib/python3.6/site-packages/kekas/keker.py\u001b[0m in \u001b[0;36m_run_epoch\u001b[0;34m(self, epoch, epochs)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/aseg_torch1/lib/python3.6/site-packages/kekas/keker.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \"\"\"\n\u001b[1;32m    474\u001b[0m         preds = self.step_fn(model=self.state.core.model,\n\u001b[0;32m--> 475\u001b[0;31m                              batch=self.state.core.batch)\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreds_key\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-178e21faa00f>\u001b[0m in \u001b[0;36mstep_fn\u001b[0;34m(model, batch)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# you could define here whatever logic you want\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m  \u001b[0;31m# here we get an \"image\" from our dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/aseg_torch1/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-99fdf0b69dde>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, xb)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'coords'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparseModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/aseg_torch1/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/aseg_torch1/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/aseg_torch1/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Linux_3Tb/a/SparseConvNet_aseg/sparseconvnet/ioLayers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         )\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Linux_3Tb/a/SparseConvNet_aseg/sparseconvnet/ioLayers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, dimension, metadata, spatial_size, coords, input_features, batch_size, mode)\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0moutput_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         )\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Ok, now let's start training!\n",
    "# It's as simple as:\n",
    "keker.kek_one_cycle(cycle_len=params['n_epoch'], \n",
    "                    max_lr=params['max_lr'],  \n",
    "                    div_factor=1000, increase_fraction=0.1, \n",
    "                    logdir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keker.state.core.epoch_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keker.state.core.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = keker_callbacks[0]\n",
    "cb.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keker_callbacks[0]._d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate Find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100% 32/32 [03:09<00:00,  4.23s/it, loss=2.4019]\n",
      "End of LRFinder\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let's find an 'optimal' learning rate with learning rate find procedure\n",
    "# for details please see the fastai course and this articles:\n",
    "# https://arxiv.org/abs/1803.09820\n",
    "# https://sgugger.github.io/how-do-you-find-a-good-learning-rate.html\n",
    "\n",
    "# NOTE: this is an optional step and you can skip it and use your favorite learning rate\n",
    "\n",
    "# you MUST specify the logdir to see graphics\n",
    "# keker will write a tensorboard logs into this folder\n",
    "# to see them start a tensorboard with `--logdir /path/to/logdir`\n",
    "# OR you can use keker.plot_kek_lr method (see cell below)\n",
    "keker.kek_lr(final_lr=0.1, logdir=\"logdir_lr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "name": "train/batch/loss",
         "type": "scatter",
         "uid": "3cfc8c95-69f0-48f7-9865-3696748d940c",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31
         ],
         "y": [
          3.1508469581604004,
          3.155036687850952,
          3.1586554050445557,
          3.1575560569763184,
          3.15378999710083,
          3.157327651977539,
          3.1372246742248535,
          3.147700309753418,
          3.154764175415039,
          3.154165029525757,
          3.164154291152954,
          3.139570951461792,
          3.1136326789855957,
          3.153083562850952,
          3.1389577388763428,
          3.1245481967926025,
          3.1077356338500977,
          3.121633529663086,
          3.0495405197143555,
          2.961421489715576,
          2.9264042377471924,
          2.8268916606903076,
          2.728623867034912,
          2.633754014968872,
          2.5442726612091064,
          2.4414467811584473,
          2.356302261352539,
          2.1476333141326904,
          1.9068760871887207,
          1.7697784900665283,
          1.7481977939605713,
          1.418802261352539
         ]
        }
       ],
       "layout": {
        "title": {
         "text": "batch/loss"
        },
        "yaxis": {
         "hoverformat": ".6f"
        }
       }
      },
      "text/html": [
       "<div id=\"a5aa72f6-c5bf-4b32-91db-68b25e6dfb22\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"a5aa72f6-c5bf-4b32-91db-68b25e6dfb22\")) {\n",
       "    Plotly.newPlot(\"a5aa72f6-c5bf-4b32-91db-68b25e6dfb22\", [{\"name\": \"train/batch/loss\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], \"y\": [3.1508469581604004, 3.155036687850952, 3.1586554050445557, 3.1575560569763184, 3.15378999710083, 3.157327651977539, 3.1372246742248535, 3.147700309753418, 3.154764175415039, 3.154165029525757, 3.164154291152954, 3.139570951461792, 3.1136326789855957, 3.153083562850952, 3.1389577388763428, 3.1245481967926025, 3.1077356338500977, 3.121633529663086, 3.0495405197143555, 2.961421489715576, 2.9264042377471924, 2.8268916606903076, 2.728623867034912, 2.633754014968872, 2.5442726612091064, 2.4414467811584473, 2.356302261352539, 2.1476333141326904, 1.9068760871887207, 1.7697784900665283, 1.7481977939605713, 1.418802261352539], \"type\": \"scatter\", \"uid\": \"3cfc8c95-69f0-48f7-9865-3696748d940c\"}], {\"title\": {\"text\": \"batch/loss\"}, \"yaxis\": {\"hoverformat\": \".6f\"}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"a5aa72f6-c5bf-4b32-91db-68b25e6dfb22\")) {window._Plotly.Plots.resize(document.getElementById(\"a5aa72f6-c5bf-4b32-91db-68b25e6dfb22\"));};})</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"a5aa72f6-c5bf-4b32-91db-68b25e6dfb22\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"a5aa72f6-c5bf-4b32-91db-68b25e6dfb22\")) {\n",
       "    Plotly.newPlot(\"a5aa72f6-c5bf-4b32-91db-68b25e6dfb22\", [{\"name\": \"train/batch/loss\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], \"y\": [3.1508469581604004, 3.155036687850952, 3.1586554050445557, 3.1575560569763184, 3.15378999710083, 3.157327651977539, 3.1372246742248535, 3.147700309753418, 3.154764175415039, 3.154165029525757, 3.164154291152954, 3.139570951461792, 3.1136326789855957, 3.153083562850952, 3.1389577388763428, 3.1245481967926025, 3.1077356338500977, 3.121633529663086, 3.0495405197143555, 2.961421489715576, 2.9264042377471924, 2.8268916606903076, 2.728623867034912, 2.633754014968872, 2.5442726612091064, 2.4414467811584473, 2.356302261352539, 2.1476333141326904, 1.9068760871887207, 1.7697784900665283, 1.7481977939605713, 1.418802261352539], \"type\": \"scatter\", \"uid\": \"3cfc8c95-69f0-48f7-9865-3696748d940c\"}], {\"title\": {\"text\": \"batch/loss\"}, \"yaxis\": {\"hoverformat\": \".6f\"}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"a5aa72f6-c5bf-4b32-91db-68b25e6dfb22\")) {window._Plotly.Plots.resize(document.getElementById(\"a5aa72f6-c5bf-4b32-91db-68b25e6dfb22\"));};})</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "name": "train/batch/lr",
         "type": "scatter",
         "uid": "a42398fb-047c-41dd-821f-cf43a25d134e",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31
         ],
         "y": [
          9.999999974752427e-07,
          1.4497406937152846e-06,
          2.1017481230956037e-06,
          3.046989604627015e-06,
          4.417344825924374e-06,
          6.404004125215579e-06,
          9.284145562560298e-06,
          1.3459602996590547e-05,
          1.951293415913824e-05,
          2.8288694011280313e-05,
          4.101126978639513e-05,
          5.945570592302829e-05,
          8.619535947218537e-05,
          0.00012496091949287802,
          0.0001811609254218638,
          0.0002626363420858979,
          0.0003807546163443476,
          0.0005519954138435423,
          0.0008002502145245671,
          0.0011601552832871675,
          0.00168192433193326,
          0.0024383540730923414,
          0.0035349810495972633,
          0.005124805960804224,
          0.007429639343172312,
          0.010771050117909908,
          0.015615230426192284,
          0.02263803407549858,
          0.03281927853822708,
          0.04757944494485855,
          0.06897785514593124,
          0.10000000149011612
         ]
        }
       ],
       "layout": {
        "title": {
         "text": "batch/lr"
        },
        "yaxis": {
         "hoverformat": ".6f"
        }
       }
      },
      "text/html": [
       "<div id=\"0cb55059-5750-4cc6-ab3c-42bf86a74671\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"0cb55059-5750-4cc6-ab3c-42bf86a74671\")) {\n",
       "    Plotly.newPlot(\"0cb55059-5750-4cc6-ab3c-42bf86a74671\", [{\"name\": \"train/batch/lr\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], \"y\": [9.999999974752427e-07, 1.4497406937152846e-06, 2.1017481230956037e-06, 3.046989604627015e-06, 4.417344825924374e-06, 6.404004125215579e-06, 9.284145562560298e-06, 1.3459602996590547e-05, 1.951293415913824e-05, 2.8288694011280313e-05, 4.101126978639513e-05, 5.945570592302829e-05, 8.619535947218537e-05, 0.00012496091949287802, 0.0001811609254218638, 0.0002626363420858979, 0.0003807546163443476, 0.0005519954138435423, 0.0008002502145245671, 0.0011601552832871675, 0.00168192433193326, 0.0024383540730923414, 0.0035349810495972633, 0.005124805960804224, 0.007429639343172312, 0.010771050117909908, 0.015615230426192284, 0.02263803407549858, 0.03281927853822708, 0.04757944494485855, 0.06897785514593124, 0.10000000149011612], \"type\": \"scatter\", \"uid\": \"a42398fb-047c-41dd-821f-cf43a25d134e\"}], {\"title\": {\"text\": \"batch/lr\"}, \"yaxis\": {\"hoverformat\": \".6f\"}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"0cb55059-5750-4cc6-ab3c-42bf86a74671\")) {window._Plotly.Plots.resize(document.getElementById(\"0cb55059-5750-4cc6-ab3c-42bf86a74671\"));};})</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"0cb55059-5750-4cc6-ab3c-42bf86a74671\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"0cb55059-5750-4cc6-ab3c-42bf86a74671\")) {\n",
       "    Plotly.newPlot(\"0cb55059-5750-4cc6-ab3c-42bf86a74671\", [{\"name\": \"train/batch/lr\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], \"y\": [9.999999974752427e-07, 1.4497406937152846e-06, 2.1017481230956037e-06, 3.046989604627015e-06, 4.417344825924374e-06, 6.404004125215579e-06, 9.284145562560298e-06, 1.3459602996590547e-05, 1.951293415913824e-05, 2.8288694011280313e-05, 4.101126978639513e-05, 5.945570592302829e-05, 8.619535947218537e-05, 0.00012496091949287802, 0.0001811609254218638, 0.0002626363420858979, 0.0003807546163443476, 0.0005519954138435423, 0.0008002502145245671, 0.0011601552832871675, 0.00168192433193326, 0.0024383540730923414, 0.0035349810495972633, 0.005124805960804224, 0.007429639343172312, 0.010771050117909908, 0.015615230426192284, 0.02263803407549858, 0.03281927853822708, 0.04757944494485855, 0.06897785514593124, 0.10000000149011612], \"type\": \"scatter\", \"uid\": \"a42398fb-047c-41dd-821f-cf43a25d134e\"}], {\"title\": {\"text\": \"batch/lr\"}, \"yaxis\": {\"hoverformat\": \".6f\"}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"0cb55059-5750-4cc6-ab3c-42bf86a74671\")) {window._Plotly.Plots.resize(document.getElementById(\"0cb55059-5750-4cc6-ab3c-42bf86a74671\"));};})</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "keker.plot_kek_lr(logdir=\"logdir_lr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Ok, now let's start training!\n",
    "# It's as simple as:\n",
    "keker.kek_one_cycle(cycle_len=params['n_epoch'], \n",
    "                    max_lr=params['max_lr'],  \n",
    "                    div_factor=1000, increase_fraction=0.1, \n",
    "                    logdir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keker.plot_kek(logdir=logdir, metrics=[\"val_iouf\", \"train_iouf\"], step=\"epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "469.333px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
